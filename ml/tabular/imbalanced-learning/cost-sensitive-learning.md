# Cost-sensitive Learning

## 1. **불균형 데이터 문제와 비용 민감 접근의 필요성**

***

실제 머신러닝 실무에서는 클래스 분포가 극도로 불균형(imbalanced)한 경우가 흔합니다. 예를 들어 신용카드 **사기 탐지**에서는 사기 거래보다 정상 거래가 훨씬 많고, 의료 분야의 **희귀 질환 진단**에서는 환자 데이터 중 병을 가진 사례가 매우 드뭅니다. 이런 경우 단순 정확도(accuracy)를 최대화하려고 하면, 모델이 소수 클래스를 거의 무시하고 다수 클래스로만 예측해도 높은 정확도를 얻을 수 있습니다. 그러나 이는 원하는 결과가 아니며, 특히 잘못 분류된 유형에 따라 심각한 문제가 될 수도 있습니다. 예를 들어 **의료 진단**에서는 환자가 실제로 암인데 검진에서 놓치는 **거짓 음성(False Negative)** 오류가, 건강한 사람을 암으로 오진하는 **거짓 양성(False Positive)** 오류보다 훨씬 심각한 결과를 초래합니다 . 마찬가지로 **보험 사기 탐지**에서도 사기 청구를 놓쳐서 지급해버리는 실수(FN)가 정상 청구를 의심하여 조사하는 실수(FP)보다 기업에 더 큰 피해를 줍니다 . 이처럼 **한 쪽 종류의 오분류가 다른 쪽보다 훨씬 큰 피해나 비용**을 유발하는 사례가 많습니다. 그런데 일반적인 학습 알고리즘은 모든 오류를 동일하게 취급하기 때문에 이러한 문제에서 적절히 대응하지 못합니다. 실제로 불균형 데이터에서는 드문 긍정(양성) 사례를 놓치지 않는 것이 핵심 목표인 경우가 많지만, 기본 모델은 이를 충분히 고려하지 못하는 것이죠.

비용 민감 학습(Cost-Sensitive Learning)은 이런 상황을 다루기 위한 머신러닝의 하위 분야로, **오분류 유형별로 상이한 비용을 고려하여 학습**하는 방법입니다 . 즉, 모델 학습이나 예측 시에 잘못 예측에 따른 **패널티**를 명시적으로 부여하여, 모든 오류를 똑같이 보는 대신 **더 비싼 오류를 피하도록 모델을 유도**합니다 . 특히 불균형 분류 문제에서 비용 민감 기법은 소수 클래스 검출의 중요성을 반영함으로써 문제를 완화할 수 있습니다 . 이 글에서는 비용 민감 분류의 기본 개념과 수식, 주요 접근 전략(훈련 단계의 변경 vs. 예측 단계의 변경 등), 그리고 **사기 탐지**와 같은 실제 사례를 통해 장점과 한계를 알아보겠습니다.

## **2. 비용 민감 분류의 기본 개념**

***

### **2.1. 개요 및 정의**

일반적인 이진 분류에서 모델은 예측 결과와 실제 값 사이의 혼동 행렬(confusion matrix)로 성능을 평가합니다. 이 행렬의 각 셀은 True Positive, False Positive, False Negative, True Negative와 같은 이름으로 불리는 예측-실제 조합의 건수를 담습니다. **비용 민감 분류**에서는 이 혼동 행렬의 각 경우에 **비용(cost)을 할당한 비용 행렬(cost matrix)**&#xC744; 정의합니다. 예컨대 이진 분류에서 행이 모델의 예측 클래스, 열이 실제 클래스라고 하면, 비용 행렬 C의 원소 C(1,0)은 모델이 1(양성)로 예측했지만 실제는 0(음성)인 경우, 즉 **거짓 양성(FP)** 하나에 대한 비용을 의미합니다. 마찬가지로 C(0,1)은 **거짓 음성(FN)** 하나의 비용입니다. 일반적으로 **올바른 분류에는 비용 0**을 부여하므로 C(0,0)와 C(1,1)는 0으로 놓습니다. 비용 행렬은 상황에 따라 달라지지만, 핵심은 한쪽 유형의 오분류 비용을 크게 설정하여 모델이 그 오류를 최소화하도록 유도하는 것입니다. **비용 민감 학습의 목표는 총 비용의 최소화**이며, 이는 곧 모델이 이러한 비용 가중치를 고려해 예측 오류를 줄이도록 만드는 것입니다.

비용 행렬이 주어졌을 때, 분류 모델의 총 비용(Total Cost)은 쉽게 계산할 수 있습니다. 예를 들어 위 정의에 따르면, 전체 모델의 비용은 다음과 같습니다:

$$
\text{Total Cost} = C(0,1) \times (\# \text{False Negatives}) + C(1,0) \times (\# \text{False Positives})\,.
$$

모델은 이 **비용 가중 오분류 수**를 최소화하는 방향으로 학습되거나 설정되어야 합니다. 이는 기존의 오류 개수 최소화(정확도 최대화) 목표를 일반화한 것으로 볼 수 있습니다. 예를 들어, 만약 C(0,1) (FN의 비용)이 C(1,0) (FP의 비용)보다 훨씬 크다면, 총 비용을 줄이기 위해 모델은 거짓 음성을 줄이는데 집중하게 되고, 다소의 거짓 양성을 감수하게 됩니다 . 반대로 FP 비용이 더 크다면 거짓 양성을 줄이는 방향으로 결정 경계가 움직일 것입니다.

### **2.2. 의사결정 경계와 임곗값**

비용 민감 분류에서 중요한 것은 **결정 임곗값(decision threshold)**&#xC758; 조정입니다. 일반적으로 이진 분류기는 $$P(Y=1 \mid \mathbf{x})$$ 즉 양성일 확률 추정치를 산출하고, 관례적으로 0.5를 경계로 양성/음성을 예측합니다. 하지만 비용을 고려한다면 최적의 임곗값  $$\tau^*$$ 는 0.5가 아닐 수 있습니다. 예를 들어 **거짓 양성의 비용**을 $$C_{FP}$$, **거짓 음성의 비용**을  $$C_{FN}$$ 이라고 하면, **Bayes 최적 결정 임계값**은 다음과 같이 주어집니다:

$$
\tau^* = \frac{C_{FP}}{\,C_{FP} + C_{FN}\,}\,
$$

즉 $$P(Y=1\mid \mathbf{x}) > \tau^*$$ 이면 양성으로 예측하고, 아니면 음성으로 예측하는 것이 기대 비용을 최소화하는 결정 규칙이 됩니다. 이 수식에서 볼 수 있듯이, 거짓 음성의 비용 $$C_{FN}$$이 클수록  $$\tau^*$$ 값은 작아집니다. 이는 모델이 양성으로 판단하는 기준을 낮추어 **더 많은 케이스를 긍정(희귀) 클래스로 분류**하게 만들며, 그만큼 거짓 음성을 줄이려는 것입니다. 반대로 C\_{FP}가 매우 큰 문제라면  $$\tau^*$$ 가 높아져 쉽게 양성 판단을 하지 않게 됩니다.

또한 비용 민감 학습은 모델의 **결정 경계(decision boundary)** 자체를 변화시킵니다. 비용을 고려하지 않은 모델은 순수하게 확률 0.5에 경계를 두지만, 비용을 적용하면 경계가 한쪽으로 이동합니다. 예를 들어 아래는 **로지스틱 회귀 분류기**를 **비용 고려 전후**로 학습시켜 얻은 결정 경계를 비교한 그림입니다. 배경 색상의 변화는 모델이 예측하는 양성 확률(파란색≈0, 붉은색≈1)을 나타내고, 점은 실제 데이터 분포(파란 점=음성 클래스, 주황 점=양성 클래스)를 나타냅니다.

일반 로지스틱 회귀 모델을 불균형 데이터에 학습시킨 경우의 결정 경계입니다 (비용 민감 요소 없음). 가운데 희미한 **흰색 경계선** 부근이 양성과 음성 클래스의 확률이 50%로 균형을 이루는 구간으로, 경계가 다소 오른쪽(양성 쪽)으로 치우쳐져 있음을 알 수 있습니다. 이는 소수 클래스(양성)에 대한 **민감도**가 낮아 거짓 음성이 상당히 발생할 수 있음을 시사합니다. 실제로 오른쪽 그림(테스트 데이터)에서 주황색 점들(양성 클래스) 상당수가 파란색 영역에 위치해 있어 양성임에도 음성으로 분류될 가능성이 있음을 보여줍니다.

반면, **비용 민감 학습**(예: 양성 클래스 오류에 높은 비용 부여)을 적용한 로지스틱 회귀의 결정 경계입니다. 희귀한 양성 오류를 줄이도록 학습한 결과, 결정 경계가 **왼쪽으로 이동**하여 더 넓은 영역을 양성으로 분류합니다. 오른쪽 테스트 데이터 그래프를 보면, 이전보다 주황색 점들이 붉은색 또는 흰색 경계 근처에 위치하여 **양성으로 판별**되는 비율이 늘어남을 확인할 수 있습니다. 이러한 변화로 인해 소수 클래스에 대한 재현율(Recall)과 균형 정확도(Balanced Accuracy)가 크게 향상됩니다. 이처럼 비용 민감 학습은 **결정 경계를 조정**함으로써 비용이 큰 오류(여기서는 거짓 음성)를 적극적으로 줄이는 방향으로 모델을 최적화합니다.

### **2.3. 비용 행렬의 설정**

비용 민감 분류에서 비용 값 C(1,0)과 C(0,1)을 어떻게 정할지는 성능에 큰 영향을 미칩니다 . 이상적으로는 도메인 전문가의 지식이나 비즈니스 요구사항을 반영하여 **현실 세계 비용**을 정확히 수치화할 수 있다면 가장 좋습니다. 예를 들어 보험 사기 탐지의 경우, 거짓 양성(FP)은 조사 인력 시간과 고객 불편 등의 비용이 있지만, 거짓 음성(FN)은 부정 지급액 손실과 회사 평판 훼손 등 **직간접적인 금전적 손실**로 이어지므로 이를 금액으로 환산해 비용 행렬을 정할 수 있을 것입니다. 하지만 의료 진단처럼 거짓 음성의 피해를 **돈**으로 환산하기 어려운 경우도 있습니다. 이러한 경우 비용 값을 임의로 설정하기보다는, **모델 선택 과정에서 비용 값을 하이퍼파라미터로 간주**하여 최적값을 탐색하기도 합니다.

명시적인 정보가 없을 때 많이 사용하는 **휴리스틱**은 **클래스 불균형 비율**을 비용에 반영하는 것입니다. 예를 들어 데이터의 양성:음성 비율이 1:100이라면, 흔히 **FN의 비용을 100, FP의 비용을 1**로 두어 소수 클래스 실수에 100배 패널티를 주곤 합니다. 이렇게 하면 다수 클래스(음성) 100건 중 1건의 실수를 소수 클래스(양성) 1건의 실수와 대등하게 취급하겠다는 의미가 됩니다. 이 방식은 간편하고 **초기 값**으로 유용하지만, 데이터가 매우 적거나 클래스 간 경계가 모호한 경우에는 최적이 아닐 수 있습니다. 따라서 필요시 교차 검증 등을 통해 여러 비용 설정을 시험해보며 모델의 **비용 민감 성능**(예: 비용 가중된 손실이나 특정 비즈니스 지표)을 비교하는 것이 바람직합니다.

## **3. 비용 민감 학습의 주요 접근 전략**

***

비용 민감 분류 문제를 다루는 방법은 크게 **모델 훈련 단계에서 비용을 고려하는 방법**과 **예측 단계(결정 결과)에서 비용을 고려하는 방법**으로 나눌 수 있습니다. 또한 두 가지를 조합한 **하이브리드 접근**이나 비용 민감 기능을 통합한 앙상블 기법도 연구되어 왔습니다. 각 접근의 개념과 특징을 살펴보겠습니다.

### **3.1. 비용을 고려한 모델 훈련 (Cost-Sensitive Training)**

**모델 학습 단계에서 비용을 직접 반영하는 방법**은, 쉽게 말해 **손실 함수에 비용 가중치를 부여**하여 모델이 학습 시에 비용이 큰 오류를 더 많이 벌하도록 만드는 접근입니다. 대부분의 머신러닝 알고리즘은 훈련 시 오류(error) 또는 손실(loss)을 최소화하도록 되어 있는데, 비용 민감 훈련에서는 이 손실 계산에 비용 행렬 값을 반영합니다. 예를 들어 **로지스틱 회귀**의 경우 클래스 1(양성) 표본에 w\_1, 클래스 0(음성) 표본에 w\_0라는 가중치를 주어 **가중 크로스 엔트로피 손실**을 사용하면, w\_1과 w\_0의 비율이 곧 FP와 FN 비용의 상대적 비중을 결정합니다. 흔히 w\_1을 다수 클래스 대비 높게 설정하여 소수 클래스 오류에 페널티를 크게 주는데, 이는 사이킷런 등에서 `class_weight="balanced"` 옵션으로 자동 적용할 수 있습니다 (이 경우 내부적으로 $$w_i \propto 1/\text{class}$$로 설정되어 앞서 언급한 불균형 비율 휴리스틱과 맥락을 같이합니다). 또는 사용자가 비용 행렬에 따라 직접 class\_weight={0:c\_{10}, 1:c\_{01\}} 형식으로 가중치를 지정할 수도 있습니다 .

이러한 비용 가중 학습을 하면 **훈련 과정에서** 모델이 **소수 클래스 오류를 줄이는 방향으로 파라미터를 업데이트**합니다. 가중치를 부여하지 않은 경우와 비교해보면, 비용 민감 학습은 소수 클래스 데이터 포인트의 **기여도가 증가**하므로 모델이 결정 경계를 해당 데이터 쪽으로 더 치우치게 됩니다 . 앞서 로지스틱 회귀 예시에서 살펴봤듯이, 이는 경계가 소수 클래스 쪽으로 이동하여 거짓 음성을 줄이는 효과로 나타납니다. 사이킷런의 DecisionTreeClassifier나 SVM (SVC) 등에서도 class\_weight 파라미터를 지원하며, **비용 민감 의사결정나무**나 **비용 민감 SVM**과 같은 알고리즘 변형은 사실상 이와 동일한 아이디어입니다. 더 나아가 XGBoost나 딥러닝 프레임워크에서도 클래스 가중치를 적용하거나 커스텀 손실 함수를 정의하여 비용 민감 학습을 구현할 수 있습니다. 실제로 **딥러닝** 분야 연구에서도 불균형 데이터를 다룰 때 비용 민감 접근이 응용되고 있으며, 클래스별 비용을 학습 과정에 통합한 예가 보고되어 있습니다. 한 예로, Khan 등(2017)은 신경망 훈련 시 비용 행렬을 함께 최적화하여 데이터 분포를 변경하지 않고(cost-insensitive) 성능을 향상시키는 방법을 제안하였습니다. 비용을 고려한 훈련의 장점은 **데이터 재샘플링 없이**도 희귀 클래스에 집중할 수 있어 효율적이고, 모델 내부적으로 비용에 최적화된 매개변수를 학습하게 된다는 점입니다.

다만 비용 가중치를 너무 극단적으로 주면 훈련이 불안정해지거나 과적합 위험이 증가할 수 있으므로 유의해야 합니다. 예를 들어 신경망에서 한 쪽 클래스의 오차에 지나치게 큰 가중치를 부여하면 경사가 한쪽으로 치우쳐 학습이 수렴하지 않을 수 있습니다. 따라서 적절한 비용 값의 선택이 중요하며, 필요하다면 비용 값을 조절하면서 검증을 통해 최적의 균형을 찾아야 합니다.

### **3.2. 예측 단계에서의 비용 고려 (Threshold Moving 등)**

모델을 훈련할 때는 특별한 처리 없이 진행하되, **예측 단계에서 결정 임계값을 조정**함으로써 비용 민감도를 부여하는 접근도 널리 쓰입니다. 이를 흔히 **임계값 이동(threshold moving)** 또는 **후처리 단계에서의 비용 최적화**라고 합니다. 기본 아이디어는 간단합니다. 모델이 출력한 **양성 확률** $$P(Y=1\mid \mathbf{x})$$ 값을 0.5 대신 다른 기준 $$\tau$$와 비교하여 양성/음성을 결정하는 것입니다. 이 $$\tau$$는 앞서 도출한 것처럼 비용 비율에 따라 산정할 수도 있고, 별도의 **검증 데이터셋**을 이용해 여러 후보 임계값에 대한 **평균 비용**을 계산한 뒤 최소화하는 값으로 선택할 수도 있습니다. 사이킷런에서는 이러한 작업을 돕기 위해 ThresholdMover나 TunedThresholdClassifierCV와 같이 비용 함수에 최적화된 임계값을 찾는 도구를 제공하기도 합니다.

임계값 조정은 구현이 용이하며, 이미 학습된 분류 모델에도 적용할 수 있다는 실용적인 장점이 있습니다. 예를 들어 확률 출력이 가능한 **랜덤 포레스트**나 **신경망** 모델을 훈련해둔 다음, 운영 단계에서 **비즈니스 요구사항**에 맞춰 FP/FN의 **허용 수준**을 조절하고 싶다면, 해당 모델의 결정 임계값만 바꿔서 비용 민감하게 사용할 수 있습니다. 실제로 많은 현업 프로젝트에서 모델 학습은 일단 기본적으로 하고, 이후에 필요에 따라 임계점을 조정하는 식으로 **정밀도-재현율 트레이드오프**를 관리합니다. 임계값 이동은 **이진 분류**뿐 아니라 다중 분류에서도 (한 vs rest 방식 등으로) 확장할 수 있지만, 각 클래스별 비용을 따로 고려해야 하므로 이 글에서는 이진 경우에 집중하겠습니다.

한 가지 유의점은 임곗값 조정이 **모델의 확률 출력의 신뢰성, 즉 칼리브레이션(calibration)**&#xC5D0; 영향을 받는다는 것입니다. 모델이 출력 확률을 정확히 예측하지 못한다면, 임계값을 조정해도 기대한 만큼 비용 최적화가 되지 않을 수 있습니다. 따라서 필요하다면 Platt Scaling이나 Isotonic Regression 같은 **확률 보정** 기법으로 모델 출력 확률을 보정한 후 임계값을 결정하면 더 효과적입니다. 그래야 비용 민감 임계값 전략이 실제 현업 환경에서도 일관되게 효과를 발휘할 수 있습니다.

### **3.3. 하이브리드 및 기타 비용 민감 기법**

**하이브리드 접근**이란 말 그대로 **데이터 수준의 처리 + 알고리즘 수준의 비용 고려**를 함께 활용하거나, 비용 민감 개념을 메타 기법에 적용한 경우를 의미합니다. 여러 방법이 제안되어 있지만, 이 중 대표적인 몇 가지를 소개하겠습니다.

* **비용 기반 데이터 재샘플링:** 앞서 모델 훈련 단계에서 비용을 적용하는 대신, 훈련 데이터 자체를 조정(resampling)하여 비용 민감 효과를 내는 방법입니다. 예를 들어 비용 행렬이 정해져 있을 때, 비용이 큰 오류(예: 양성 클래스 오류)가 발생하지 않도록 소수 클래스 샘플을 비용 비율만큼 증폭(oversampling)하거나 다수 클래스 샘플을 축소(undersampling)하는 것입니다. 이러한 방법을 문헌에서는 **cost-proportionate sampling** 혹은 **cost-proportionate weighting**이라고 부르기도 합니다. 이 기법은 별도의 알고리즘 수정 없이도 비용 민감 효과를 낼 수 있지만, 너무 과도한 재샘플링은 데이터 분포를 왜곡시켜 과적합을 야기할 수 있으므로 적절한 수준으로 사용해야 합니다. 또한 클래스별 비용 외에 개별 샘플의 중요도가 다를 때(예: 거래 금액이 큰 사기 사례)에는 해당 샘플을 반복시키는 방식으로 비용을 반영할 수도 있습니다.
* **메타러닝 기법 (예: MetaCost)**: 비용 민감 기능을 기존 분류기에 입혀주는 **래퍼(wrapper) 방법**도 있습니다. 그 중 하나인 **MetaCost**는 예측 단계가 아니라 **훈련 데이터 레이블을 변경**하는 접근입니다. 구체적으로, 먼저 원 데이터로 여러 분류기(예: 배깅 ensemble)를 학습시켜 각 샘플이 양성일 **비용-민감 확률**을 추정합니다. 그리고 그 확률이 일정 기준을 넘으면 해당 샘플의 라벨을 소수 클래스로 바꾸는 식으로 **데이터를 재레이블링**합니다. 이렇게 비용을 고려해 변환된 데이터를 최종 분류기에 다시 학습시키면, 원래 비용 민감하지 않았던 분류기도 비용을 고려한 성능을 내도록 만들 수 있습니다. MetaCost의 장점은 임의의 분류기에도 적용 가능하다는 것이지만, 두 단계 학습이 필요해 다소 복잡합니다.
* **비용 민감 앙상블(Ensemble)**: 결정 트리 앙상블 등에도 비용 개념을 녹여낸 알고리즘들이 있습니다. 대표적으로 **AdaCost**는 AdaBoost에 비용 개념을 추가한 알고리즘으로, 부스팅 반복 과정에서 잘못 분류된 샘플의 **가중치 업데이트 시 비용을 함께 고려**합니다. 비용이 큰 오류를 저지른 샘플은 다음 라운드에 더 크게 가중되고, 비용이 낮은 오류에 대해서는 적게 가중하여, 최종적으로 부스팅 모델이 높은 비용 오류를 최소화하도록 유도하는 방식입니다 . 이외에도 비용 민감 결정트리(pruning 시 비용 고려 등)나 비용 민감 SVM(C 값 조정) 등이 연구되어 왔지만, 최근에는 클래스 가중치를 적용하는 간단한 방법으로도 거의 동일한 효과를 얻을 수 있어 실용적으로는 앞서 언급한 방법들이 더 많이 쓰입니다.

요약하면, 비용 민감 문제를 다루는 전략은 **데이터 수준에서 클래스 불균형을 보정**하거나, **알고리즘 수준에서 손실 함수를 수정**하거나, **예측 결과를 후처리**하는 방식으로 구현될 수 있습니다. 현업에서는 종종 이들을 적절히 **조합**하여 사용합니다. 예를 들어 매우 불균형한 데이터셋일 경우 소수 클래스를 약간 **오버샘플링**한 후, **클래스 가중치**를 적용해 학습하고, 최종적으로 **임계값 조정**까지 해서 목표 지표(예: 재무적 손실 최소화)를 만족시키는 식으로 단계별 튜닝을 하기도 합니다. 가장 중요한 것은 적용 분야에서 어떤 오류를 얼마나 **심각하게 여겨야 하는지**를 명확히 하고, 그것을 모델에 반영하는 최적의 방법을 찾는 것입니다.

## **4. 적용 사례: 비용 민감 학습의 활용**

***

앞서 언급한 사기 탐지(Fraud Detection)를 다시 예로 들어보겠습니다. 신용카드 거래 데이터를 다루는 모델에서 **거짓 음성**은 곧 사기 거래를 놓치는 것을 의미하며, 이는 해당 거래 금액의 손실뿐 아니라 **추가적인 사기 시도**로 인한 더 큰 손실, 그리고 **회사 평판 손상**까지 야기할 수 있습니다. 반면 **거짓 양성**은 정상 거래를 일시적으로 차단하거나 조사하는 것으로, 고객의 불편과 소량의 조사 비용이 들지만 기업에 치명적이지는 않습니다. 따라서 대부분의 금융 기관은 거짓 음성의 비용을 거짓 양성보다 훨씬 높게 책정하여 (예를 들어 1건의 사기 놓침 = 100건의 정상 거래 차단에 맞먹는 비용으로 간주) **비용 민감 분류 모델**을 구축합니다. 이를 통해 **적발률**을 극대화하고, 비록 false alarm이 다소 늘더라도 전체 **예상 손실액**을 최소화하는 전략을 취합니다.

의료 분야에서도 비용 민감 학습이 필수적입니다. 예를 들어 암 진단 모델에서 한 명의 환자를 놓치는 것(FN)은 여러 명의 환자를 잘못 양성으로 분류하는 것(FP)보다 훨씬 큰 영향을 가집니다 . 그러므로 암 환자를 **False Negative=0**으로 만들겠다는 각오로 모델을 설계하기도 합니다. 비용 행렬로 치면 FN에 매우 큰 비용을 두어 그런 오류가 거의 발생하지 않도록 학습시키는 것이죠. 실제 병원에서 이런 모델을 쓰면, 양성으로 예측된 환자 중 일부는 추가 검사에서 암이 아니라고 판명날 수 있지만(즉 FP 발생), **암 환자가 누락되는 일은 없도록** 함으로써 궁극적으로 의료 서비스의 목표를 달성할 수 있습니다.

또 다른 예로, **대출 사기/연체 예측** 모델을 생각해봅시다. 은행 입장에서 **거짓 양성**은 갚을 능력이 있는 고객을 잘못 거절한 경우이고, **거짓 음성**은 갚지 못할 사람에게 대출을 승인한 경우입니다. 당연히 후자가 은행에 금전적 타격이 크므로, 비용 민감 모델은 거짓 음성을 줄이도록 설계됩니다. 이를테면 우수 고객을 일부 놓치더라도(기회 손실) 부실 대출을 최소화하는 방향으로 모델 임계값을 높게 잡거나, 손실 함수에 비용을 부여해 학습하는 것입니다.

이 밖에도 **침입 탐지**(정상 트래픽을 공격으로 오인 vs. 실제 공격을 놓침), **제조 품질 검수**(양품을 불량으로 판단 vs. 불량을 놓침) 등 많은 분야에서 오류 유형별 비용이 크게 차이나며, 비용 민감 학습이 성능을 좌우합니다. 중요한 것은 도메인 지식과 비즈니스 우선순위를 토대로 **명시적인 비용 지표**를 마련하고, 이를 모델에 녹여내는 것입니다.

## **5. 비용 민감 학습의 장점과 한계**

***

### **5.1. 장점**

비용 민감 학습의 가장 큰 장점은 **모델이 현실에서 중요한 목표에 직접 최적화**된다는 점입니다. 즉, 단순한 정확도 대신 실제 **비용/이익** 기준으로 모델을 평가·학습시킴으로써, 궁극적으로 업무에 더 도움이 되는 결과를 얻습니다. 예를 들어 비용 민감 모델은 낮은 빈도로 일어나는 중요한 이벤트(사기, 이상징후 등)를 더 잘 포착하여 **실제 업무 손실을 줄일 수 있습니다**. 둘째, 비용 민감 접근은 **데이터를 인위적으로 증강하지 않고도** 불균형 문제를 완화할 수 있습니다. 이는 과적합을 줄이고 학습 속도를 높이는 데 유리합니다. 오버샘플링처럼 데이터 양을 불리는 경우 모델 훈련 시간이 증가하고 노이즈가 들어갈 우려가 있는데, 비용 가중 학습은 그런 부작용 없이도 효과를 낼 수 있습니다. 셋째, 비용 민감 기법은 **기존 알고리즘과 쉽게 결합**될 수 있어 구현이 비교적 간단합니다. 사이킷런의 class\_weight 같은 기본 기능을 사용하거나, 예측 확률을 활용한 임계값 조정만으로도 적용 가능하므로, 복잡한 커스텀 모델 없이도 현업에 도입하기 수월합니다. 마지막으로, 비용 민감 학습은 **다중 클래스 분류**로도 확장 가능합니다. 이때는 각 클래스 간 혼동쌍마다 비용을 정의해야 하지만, 원칙적으로 비용 행렬을 $$n\times n$$으로 늘리면 동일한 개념을 적용할 수 있습니다 (예: 제품 추천에서 특정 클래스 상품을 놓친 비용이 다른 클래스보다 큰 경우 등). 즉, 이 방법은 이진 분류에 국한되지 않고 폭넓게 활용될 수 있습니다.

### **5.2. 한계**

한편, 비용 민감 학습에는 몇 가지 현실적인 어려움과 trade-off가 존재합니다. **첫째**, **비용 산정의 어려움**입니다. 모든 분야에 대해 FP와 FN의 비용을 명확히 수치화하기 어렵습니다. 때로는 비용을 금전적으로 평가할 수 없거나(예: 인명 피해), 조직 내 합의가 힘들 수도 있습니다. 잘못된 비용 설정은 모델을 잘못된 방향으로 최적화시켜 **오히려 성능을 악화**시킬 위험이 있습니다. **둘째**, 비용 민감 모델은 특정 오류를 줄이는 대신 다른 유형의 오류가 늘어나는 **풍선효과**가 있습니다. 이는 본질적으로 정밀도와 재현율의 트레이드오프와 맞물린 것으로, 사업적으로 그 균형이 타당한지 검토해야 합니다. 예컨대 사기 탐지에서 모든 사기를 잡으려다 보면 정상 거래의 false alarm이 과도하게 늘어나 **고객 불편**이 커질 수 있습니다. 그러므로 적정한 비용 비율을 찾는 것이 중요합니다. **셋째**, 극단적으로 불균형한 데이터에서는 비용을 고려해도 **데이터 자체의 한계**를 완전히 극복하기 어렵습니다. 소수 클래스에 정보가 너무 부족하면 가중치를 높여도 모델이 학습할 패턴이 없기 때문에, 이 경우 추가 데이터 확보나 특성 엔지니어링, 혹은 합성 데이터 생성(SMOTE 등) 같은 다른 보완책이 필요할 수 있습니다. **넷째**, 비용 민감 학습은 때때로 **평가지표의 왜곡**을 일으킬 수 있습니다. 모델을 비용에 최적화하면 일반적인 정확도나 AUC 측면에서는 개선이 없거나 감소할 수 있습니다 . 따라서 여러 평가 지표를 함께 모니터링하고, 비용 관점에서 개선이 다른 중요한 지표의 허락 가능한 범위 내에 있는지 살펴봐야 합니다.

요약하면, 비용 민감 학습은 불균형 분류 문제에서 **필요불가결한 도구**이며, 잘 활용하면 모델의 실용 가치를 크게 높일 수 있습니다. 물론 정확한 비용 설정과 균형 잡힌 평가가 전제되어야 하며, 다른 기법들과 병행하여 현명하게 적용해야 최고의 효과를 볼 수 있습니다. 비용 민감 학습을 통해 모델이 정말로 “우리에게 중요한 것”을 배우게 함으로써, 머신러닝 프로젝트를 한 단계 더 비즈니스 목표에 밀착시킬 수 있을 것입니다.
