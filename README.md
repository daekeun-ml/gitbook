---
description: >-
  Disclaimer: 본 Gitbook은 저자의 개인적인 의견과 가이드로 저자가 재직 중인 회사의 공식 문서와 입장을 대변하는 것이 아니며,
  모든 내용은 저자가 재직 중인 회사의 공식 문서를 우선으로 합니다.
icon: user-hair
---

# About me

## :man\_bowing: 서문

먼저, 보잘 것 없는 페이지에 방문해 주셔서 감사합니다.

이전 직장들이 보안에 민감한 회사들이다 보니, 회사의 영업 기밀과 무관한 코드나 기술 문서도 별도로 정리할 수 없었습니다. (퇴근 이후 머릿속에 든 지식들을 public 공간에 정리했다면 가능했겠지만, 여유가 없었죠 ^^) 하지만, R\&D의 요람에서 벗어나 직접 고객들과 대면하는 직무를 맡다 보니 공식 문서들이나 예제들으로 전달하는 데에는 한계가 있었고, 저 또한 기술적인 부분의 정리가 필요하다 생각했습니다.

제가 딥러닝을 처음 접했던 2010년도만 해도 아직 오픈 소스들이 활성화되어 있지 않아 밑바닥부터 구현해야 했고, 머신 러닝의 기본적인 개념들을 이해하려고 Bishop책을 힘들게 정독했습니다. 다행히도 현재는 워낙 좋은 자료들이 넘치고 재능 기부하시는 분들이 많아 진입 장벽이 정말 많이 낮아졌다고 생각합니다.

하지만, 저는 여전히 기초가 중요하다고 생각합니다. 딥러닝을 전공하였음에도 불구하고 Linear Regression과 RBF (Radial Basis Function) 같은 구닥다리(?) 모델을 선호하며, 지금도 수학의 끈을 놓지 않으려고 합니다. (솔직히 말씀드리면 가성비가 꽝이죠...저는 이런 길을 다른 분들께 추천하지 않습니다.)

이미 훌륭한 강좌들이 많고 제 역량 부족으로 별도로 강좌로 정리할 예정은 없습니다. 하지만, 단편적으로 기술한 내용들이 조금이나마 도움이 될 수 있었으면 좋겠습니다.

## :feet: 약력

한줄요약: ML 고군분투러 (not 전문가), GenAI 왕초보 (not 전문가)

{% hint style="info" %}
중간의 공백 기간은 학업에 충실했던 기간이며, 2001\~2004년은 산업기능요원으로 근무했습니다.
{% endhint %}

* Principal AIML Specialist Solutions Architect @ Amazon Web Services (2025.06\~Current)
* Senior Technical ML Specialist @ Microsoft (2024.03\~2025.06)
* Senior AIML Specialist Solutions Architect @ Amazon Web Services (2019.06\~2024.03)
* Senior Engineer & Data Scientist @ Hyundai Card\&Capital (2017.02\~2019.06)
* Senior Research Engineer @ LG Display (2013.03\~2017.02)
* Computer Vision Research Engineer @ Atalgo (Startup) (2008.02\~2010.01)
* Assistant Manager & Web Developer @ Nara-i-net (2001.09\~2004.09)

## 📝 특허 (1저자)

* Method and Device for Generating Compensation data of Display Device (kr 10-2018-0074907)
* Display Device and Method for Driving the same (kr 10-2018-0073296)
* Prediction Method and System for Predicting a Luminance Decline of Display Device (kr 10-2017-0026974)
* Apparatus and method for Compensating of Brightness Deviation (kr 10-2016-0004136)
* Inspection Method and Device for Flat Panel Display Device (kr 10-2016-0004811)
* Method and Device of LCD Device for Generating Compensation Data (kr 10-2016-0016214)

### 📝 Tech Blog Contributions

* **Daekeun Kim** (2024). [Fine-tune/Evaluate/Quantize SLM/LLM using the torchtune on Azure ML. _Microsoft Tech Community._](https://techcommunity.microsoft.com/blog/machinelearningblog/fine-tuneevaluatequantize-slmllm-using-the-torchtune-on-azure-ml/4285663)
* **Daekeun Kim** (2024). [Generate Synthetic QnAs from Real-world Data on Azure. _Microsoft Tech Community._](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/generate-synthetic-qnas-from-real-world-data-on-azure/ba-p/4202053)
* **Daekeun Kim** (2024). [Fine-tuning Florence-2 for VQA (Visual Question Answering) using the Azure ML Python SDK and MLflow. _Microsoft Tech Community_](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/fine-tuning-florence-2-for-vqa-visual-question-answering-using/ba-p/4181123)
* Manoranjan Rajguru and **Daekeun Kim** (2024). [Fine-tune Small Language Model (SLM) Phi-3 using Azure Machine Learning. _Microsoft Tech Community._](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/finetune-small-language-model-slm-phi-3-using-azure-machine/ba-p/4130399)
* **Daekeun Kim** (2023). [Quickly build high-accuracy Generative AI applications on enterprise data using Amazon Kendra, LangChain, and LLMs. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/quickly-build-high-accuracy-generative-ai-applications-on-enterprise-data-using-amazon-kendra-langchain-and-large-language-models)
* **Daekeun Kim** (2023). [Build a powerful question answering bot with Amazon SageMaker, Amazon OpenSearch Service, Streamlit, and LangChain. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/build-a-powerful-question-answering-bot-with-amazon-sagemaker-amazon-opensearch-service-streamlit-and-langchain)
* **Daekeun Kim** (2023). [Interactively fine-tune Falcon-40B and other LLMs on Amazon SageMaker Studio notebooks using QLoRA. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/interactively-fine-tune-falcon-40b-and-other-llms-on-amazon-sagemaker-studio-notebooks-using-qlora)
* **Daekeun Kim** (2023). [Deploy Falcon-40B with large model inference DLCs on Amazon SageMaker. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/machine-learning-deploy-falcon-40b-with-large-model-inference-dlcs-on-amazon-sagemaker)
* Hyundoo Jin, **Daekeun Kim**, Daeyeol Shim, and Daehoon Oh (2023). [Using Amazon SageMaker Distributed Training with KakaoStyle to Model a Category Automated Classification System. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/amazon-sagemaker-distributed-training-for-automated-category-classification)
* **Daekeun Kim** and Hyeonsang Jeon (2023). [Train a Large Language Model on a single Amazon SageMaker GPU with Hugging Face and LoRA. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/train-a-large-language-model-on-a-single-amazon-sagemaker-gpu-with-hugging-face-and-lora)
* Sungwon Han, Heewon Ko, Hyojung Kang, Kyungdae Cho, Sanghwa Na, and **Daekeun Kim** (2023). [SK Telecom's Case Study of Building a ML Pipeline Using AWS Inferentia and AWS Step Functions. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/skt-mlops-using-aws-inferentia-stepfunctions/)

### 📕 Tech book Translation

* **Daekeun Kim** and Daeyeol Shim (2023). Co-translated “[Machine Learning System Engineering in Action](https://product.kyobobook.co.kr/detail/S000211556863)”, authored by Ben Wilson.
* **Daekeun Kim** and Youngmin Kim (2023). Co-translated “[Designing Machine Learning System](https://product.kyobobook.co.kr/detail/S000201212403)”, authored by Chip Huyen.

| Name         | URL                                                                                  |
| ------------ | ------------------------------------------------------------------------------------ |
| LinkedIn     | [https://www.linkedin.com/in/daekeun-kim/](https://www.linkedin.com/in/daekeun-kim/) |
| GitHub       | [https://github.com/daekeun-ml](https://github.com/daekeun-ml)                       |
| Hugging Face | [https://huggingface.co/daekeun-ml](https://huggingface.co/daekeun-ml)               |
