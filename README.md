---
description: >-
  Disclaimer: ë³¸ Gitbookì€ ì €ìì˜ ê°œì¸ì ì¸ ì˜ê²¬ê³¼ ê°€ì´ë“œë¡œ ì €ìê°€ ì¬ì§ ì¤‘ì¸ íšŒì‚¬ì˜ ê³µì‹ ë¬¸ì„œì™€ ì…ì¥ì„ ëŒ€ë³€í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë©°,
  ëª¨ë“  ë‚´ìš©ì€ ì €ìê°€ ì¬ì§ ì¤‘ì¸ íšŒì‚¬ì˜ ê³µì‹ ë¬¸ì„œë¥¼ ìš°ì„ ìœ¼ë¡œ í•©ë‹ˆë‹¤.
icon: user-hair
---

# About me

## :man\_bowing: ì„œë¬¸

ë¨¼ì €, ë³´ì˜ ê²ƒ ì—†ëŠ” í˜ì´ì§€ì— ë°©ë¬¸í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.

ì´ì „ ì§ì¥ë“¤ì´ ë³´ì•ˆì— ë¯¼ê°í•œ íšŒì‚¬ë“¤ì´ë‹¤ ë³´ë‹ˆ, íšŒì‚¬ì˜ ì˜ì—… ê¸°ë°€ê³¼ ë¬´ê´€í•œ ì½”ë“œë‚˜ ê¸°ìˆ  ë¬¸ì„œë„ ë³„ë„ë¡œ ì •ë¦¬í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. (í‡´ê·¼ ì´í›„ ë¨¸ë¦¿ì†ì— ë“  ì§€ì‹ë“¤ì„ public ê³µê°„ì— ì •ë¦¬í–ˆë‹¤ë©´ ê°€ëŠ¥í–ˆê² ì§€ë§Œ, ì—¬ìœ ê°€ ì—†ì—ˆì£  ^^) í•˜ì§€ë§Œ, R\&Dì˜ ìš”ëŒì—ì„œ ë²—ì–´ë‚˜ ì§ì ‘ ê³ ê°ë“¤ê³¼ ëŒ€ë©´í•˜ëŠ” ì§ë¬´ë¥¼ ë§¡ë‹¤ ë³´ë‹ˆ ê³µì‹ ë¬¸ì„œë“¤ì´ë‚˜ ì˜ˆì œë“¤ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ë°ì—ëŠ” í•œê³„ê°€ ìˆì—ˆê³ , ì € ë˜í•œ ê¸°ìˆ ì ì¸ ë¶€ë¶„ì˜ ì •ë¦¬ê°€ í•„ìš”í•˜ë‹¤ ìƒê°í–ˆìŠµë‹ˆë‹¤.

ì œê°€ ë”¥ëŸ¬ë‹ì„ ì²˜ìŒ ì ‘í–ˆë˜ 2010ë…„ë„ë§Œ í•´ë„ ì•„ì§ ì˜¤í”ˆ ì†ŒìŠ¤ë“¤ì´ í™œì„±í™”ë˜ì–´ ìˆì§€ ì•Šì•„ ë°‘ë°”ë‹¥ë¶€í„° êµ¬í˜„í•´ì•¼ í–ˆê³ , ë¨¸ì‹  ëŸ¬ë‹ì˜ ê¸°ë³¸ì ì¸ ê°œë…ë“¤ì„ ì´í•´í•˜ë ¤ê³  Bishopì±…ì„ í˜ë“¤ê²Œ ì •ë…í–ˆìŠµë‹ˆë‹¤. ë‹¤í–‰íˆë„ í˜„ì¬ëŠ” ì›Œë‚™ ì¢‹ì€ ìë£Œë“¤ì´ ë„˜ì¹˜ê³  ì¬ëŠ¥ ê¸°ë¶€í•˜ì‹œëŠ” ë¶„ë“¤ì´ ë§ì•„ ì§„ì… ì¥ë²½ì´ ì •ë§ ë§ì´ ë‚®ì•„ì¡Œë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.

í•˜ì§€ë§Œ, ì €ëŠ” ì—¬ì „íˆ ê¸°ì´ˆê°€ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì„ ì „ê³µí•˜ì˜€ìŒì—ë„ ë¶ˆêµ¬í•˜ê³  Linear Regressionê³¼ RBF (Radial Basis Function) ê°™ì€ êµ¬ë‹¥ë‹¤ë¦¬(?) ëª¨ë¸ì„ ì„ í˜¸í•˜ë©°, ì§€ê¸ˆë„ ìˆ˜í•™ì˜ ëˆì„ ë†“ì§€ ì•Šìœ¼ë ¤ê³  í•©ë‹ˆë‹¤. (ì†”ì§íˆ ë§ì”€ë“œë¦¬ë©´ ê°€ì„±ë¹„ê°€ ê½ì´ì£ ...ì €ëŠ” ì´ëŸ° ê¸¸ì„ ë‹¤ë¥¸ ë¶„ë“¤ê»˜ ì¶”ì²œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)

ì´ë¯¸ í›Œë¥­í•œ ê°•ì¢Œë“¤ì´ ë§ê³  ì œ ì—­ëŸ‰ ë¶€ì¡±ìœ¼ë¡œ ë³„ë„ë¡œ ê°•ì¢Œë¡œ ì •ë¦¬í•  ì˜ˆì •ì€ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ë‹¨í¸ì ìœ¼ë¡œ ê¸°ìˆ í•œ ë‚´ìš©ë“¤ì´ ì¡°ê¸ˆì´ë‚˜ë§ˆ ë„ì›€ì´ ë  ìˆ˜ ìˆì—ˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.

## :feet: ì•½ë ¥

í•œì¤„ìš”ì•½: ML ê³ êµ°ë¶„íˆ¬ëŸ¬ (not ì „ë¬¸ê°€), GenAI ì™•ì´ˆë³´ (not ì „ë¬¸ê°€)

{% hint style="info" %}
ì¤‘ê°„ì˜ ê³µë°± ê¸°ê°„ì€ í•™ì—…ì— ì¶©ì‹¤í–ˆë˜ ê¸°ê°„ì´ë©°, 2001\~2004ë…„ì€ ì‚°ì—…ê¸°ëŠ¥ìš”ì›ìœ¼ë¡œ ê·¼ë¬´í–ˆìŠµë‹ˆë‹¤.
{% endhint %}

* Principal AIML Specialist Solutions Architect @ Amazon Web Services (2025.06\~Current)
* Senior Technical ML Specialist @ Microsoft (2024.03\~2025.06)
* Senior AIML Specialist Solutions Architect @ Amazon Web Services (2019.06\~2024.03)
* Senior Engineer & Data Scientist @ Hyundai Card\&Capital (2017.02\~2019.06)
* Senior Research Engineer @ LG Display (2013.03\~2017.02)
* Computer Vision Research Engineer @ Atalgo (Startup) (2008.02\~2010.01)
* Assistant Manager & Web Developer @ Nara-i-net (2001.09\~2004.09)

## ğŸ“ íŠ¹í—ˆ (1ì €ì)

* Method and Device for Generating Compensation data of Display Device (kr 10-2018-0074907)
* Display Device and Method for Driving the same (kr 10-2018-0073296)
* Prediction Method and System for Predicting a Luminance Decline of Display Device (kr 10-2017-0026974)
* Apparatus and method for Compensating of Brightness Deviation (kr 10-2016-0004136)
* Inspection Method and Device for Flat Panel Display Device (kr 10-2016-0004811)
* Method and Device of LCD Device for Generating Compensation Data (kr 10-2016-0016214)

### ğŸ“ Tech Blog Contributions

* **Daekeun Kim** (2024). [Fine-tune/Evaluate/Quantize SLM/LLM using the torchtune on Azure ML. _Microsoft Tech Community._](https://techcommunity.microsoft.com/blog/machinelearningblog/fine-tuneevaluatequantize-slmllm-using-the-torchtune-on-azure-ml/4285663)
* **Daekeun Kim** (2024). [Generate Synthetic QnAs from Real-world Data on Azure. _Microsoft Tech Community._](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/generate-synthetic-qnas-from-real-world-data-on-azure/ba-p/4202053)
* **Daekeun Kim** (2024). [Fine-tuning Florence-2 for VQA (Visual Question Answering) using the Azure ML Python SDK and MLflow. _Microsoft Tech Community_](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/fine-tuning-florence-2-for-vqa-visual-question-answering-using/ba-p/4181123)
* Manoranjan Rajguru and **Daekeun Kim** (2024). [Fine-tune Small Language Model (SLM) Phi-3 using Azure Machine Learning. _Microsoft Tech Community._](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/finetune-small-language-model-slm-phi-3-using-azure-machine/ba-p/4130399)
* **Daekeun Kim** (2023). [Quickly build high-accuracy Generative AI applications on enterprise data using Amazon Kendra, LangChain, and LLMs. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/quickly-build-high-accuracy-generative-ai-applications-on-enterprise-data-using-amazon-kendra-langchain-and-large-language-models)
* **Daekeun Kim** (2023). [Build a powerful question answering bot with Amazon SageMaker, Amazon OpenSearch Service, Streamlit, and LangChain. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/build-a-powerful-question-answering-bot-with-amazon-sagemaker-amazon-opensearch-service-streamlit-and-langchain)
* **Daekeun Kim** (2023). [Interactively fine-tune Falcon-40B and other LLMs on Amazon SageMaker Studio notebooks using QLoRA. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/interactively-fine-tune-falcon-40b-and-other-llms-on-amazon-sagemaker-studio-notebooks-using-qlora)
* **Daekeun Kim** (2023). [Deploy Falcon-40B with large model inference DLCs on Amazon SageMaker. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/machine-learning-deploy-falcon-40b-with-large-model-inference-dlcs-on-amazon-sagemaker)
* Hyundoo Jin, **Daekeun Kim**, Daeyeol Shim, and Daehoon Oh (2023). [Using Amazon SageMaker Distributed Training with KakaoStyle to Model a Category Automated Classification System. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/amazon-sagemaker-distributed-training-for-automated-category-classification)
* **Daekeun Kim** and Hyeonsang Jeon (2023). [Train a Large Language Model on a single Amazon SageMaker GPU with Hugging Face and LoRA. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/train-a-large-language-model-on-a-single-amazon-sagemaker-gpu-with-hugging-face-and-lora)
* Sungwon Han, Heewon Ko, Hyojung Kang, Kyungdae Cho, Sanghwa Na, and **Daekeun Kim** (2023). [SK Telecom's Case Study of Building a ML Pipeline Using AWS Inferentia and AWS Step Functions. _AWS Korea Tech Blog._](https://aws.amazon.com/ko/blogs/tech/skt-mlops-using-aws-inferentia-stepfunctions/)

### ğŸ“• Tech book Translation

* **Daekeun Kim** and Daeyeol Shim (2023). Co-translated â€œ[Machine Learning System Engineering in Action](https://product.kyobobook.co.kr/detail/S000211556863)â€, authored by Ben Wilson.
* **Daekeun Kim** and Youngmin Kim (2023). Co-translated â€œ[Designing Machine Learning System](https://product.kyobobook.co.kr/detail/S000201212403)â€, authored by Chip Huyen.

| Name         | URL                                                                                  |
| ------------ | ------------------------------------------------------------------------------------ |
| LinkedIn     | [https://www.linkedin.com/in/daekeun-kim/](https://www.linkedin.com/in/daekeun-kim/) |
| GitHub       | [https://github.com/daekeun-ml](https://github.com/daekeun-ml)                       |
| Hugging Face | [https://huggingface.co/daekeun-ml](https://huggingface.co/daekeun-ml)               |
