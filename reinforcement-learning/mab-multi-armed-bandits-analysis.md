# MAB\(Multi-Armed Bandits\) Analysis

아래 References 중 Code를 집중해부

[Analysis.pdf](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8b30daa0-85e1-41ec-b907-adadd9d4326b/Analysis.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20201115%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20201115T133211Z&X-Amz-Expires=86400&X-Amz-Signature=d455fd2b7ded447e78be92da5513483c4546309a8d4e4586248340049f26dd4c&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Analysis.pdf%22)

### **References**

* Code: [Python library for Multi-Armed Bandits](https://github.com/bgalbraith/bandits)
  * [https://github.com/bgalbraith/bandits](https://github.com/bgalbraith/bandits)
* Theory: [Reinforcement Learning: An Introduction, 2nd edition, 2016 Sep. Draft Version](http://ufal.mff.cuni.cz/~straka/courses/npfl114/2016/sutton-bookdraft2016sep.pdf)
  * [http://ufal.mff.cuni.cz/~straka/courses/npfl114/2016/sutton-bookdraft2016sep.pdf](http://ufal.mff.cuni.cz/~straka/courses/npfl114/2016/sutton-bookdraft2016sep.pdf)
* Understanding: [SanghyukChun's Blog: Machine Learning 스터디 \(20\) Reinforcement L earning](http://sanghyukchun.github.io/76/)
  * [http://sanghyukchun.github.io/76/](http://sanghyukchun.github.io/76/)

