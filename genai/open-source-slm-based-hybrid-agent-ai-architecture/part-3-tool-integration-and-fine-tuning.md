# Part 3: Tool Integration & Fine-Tuning

#### Content Level: 200

## Suggested Pre-Reading

* [Part 1: Overview & Background](part-1-overview-and-background.md)
* [Part 2: Agentic Patterns & Prompting](part-2-agentic-patterns-and-prompting.md)

### TL;DR

This pattern integrates the SLM with RAG/VectorDB, SQL databases, internal APIs, and computation/code execution tools to perform practical tasks. Fine-tuning strategies for optimizing for enterprise environments include adjusting conversational styles, learning tool interfaces, injecting domain-specific knowledge, and chain-of-thought training. Efficient customization is possible with lightweight techniques like LoRA.

### 1. Tool Integration Patterns with SLMs

To utilize LLMs for enterprise knowledge exploration and task automation, tightly connecting external knowledge sources and software tools with LLM agents is essential. This architecture designs SLM agents to use various plugins/tools to supplement their limitations. Representative integration patterns include:

* **Search/RAG Integration**: RAG is a standard technique for supplying LLMs with latest, reliable information. SLM agents connect with internal document search engines or vector DBs to search documents matching user questions and generate answers using that content. For example, when questions like "What are this year's Q2 sales trends?" arrive, agents query internal report DBs to retrieve relevant paragraphs and generate answers based on them. Retrieved documents are presented as sources alongside answers to ensure evidence-based responses. Through RAG, SLMs can access vast knowledge bases with small parameters, gaining advantages in factuality and reflecting constantly updated information. However, searching wrong documents or ignoring search results can cause confusion, so RAG optimization fine-tuning discussed earlier trains SLMs to maximally utilize given contexts and rely on injected knowledge over model's own knowledge.
* **Table/SQL Agents**: When internal data exists in structured DBs or spreadsheets, agents can perform TextToSQL conversion, execute queries in DBs, then provide natural language explanations of results to users. Such LLM SQL agents enable non-technical users to query data just by asking questions, improving productivity. Many business intelligence (BI) scenarios actually utilize TextToSQL agents, and accuracy can be improved by fine-tuning SLMs for such purposes or providing rich prompt examples. However, when using SQL agents, read-only permissions should be used to prevent incorrect queries from affecting data quality, or steps where superior models like Claude verify query results can be included.
* **Internal API Integration**: LLMs can directly perform enterprise-specific functions (e.g., schedule creation, ticket issuance, email sending) by connecting internal web APIs or automation scripts. For instance, if customer chatbots need to "change order delivery address" per user requests, LLMs generate commands calling internal logistics system APIs and reflect results in conversations. Agent frameworks (e.g., Strands, LangGraph, CrewAI, AutoGen) enable LLMs to call functions in defined JSON formats and handle responses. For example, when SLMs generate functions like `SendEmail(to:"example@co.com", subject:"...", body:"...")`, systems send actual emails then inform models of results ("success"). Through such internal API integration, LLM agents gain practical task execution capabilities beyond simple answers. This particularly enables automating repetitive tasks (ticket processing, form completion) or using LLMs as orchestration hubs between multiple systems.
* **Calculation/Code Execution**: For tasks like mathematical calculations or coding where LLMs easily make errors, external calculator or Python executor tools are attached for solutions. For example, for questions like "What is the square root of 52?", agents call `Calculator.calculate("sqrt(52)")` and respond with results. For coding assistance agents, code snippets written by models can be immediately executed to receive error messages for corrections. Such automatic feedback loops are particularly effective at reducing small model coding errors.

Through integration of above patterns, SLM agents become **acting AI** beyond simple language responses within **rich tool ecosystems**. This is an essential condition for overcoming limitations of standalone LLMs and actual utilization in enterprise workflows. Important considerations include ensuring **models accurately understand tool definitions and usage** and establishing **safeguards against misuse**. For example, having Claude judge "Is this call appropriate?" before and after tool usage, or evaluating tool result reliability. Additionally, **Human-in-the-loop** mechanisms should be considered where logs are maintained at each integration point to monitor model behavior and receive human review when necessary.

### 2. Fine-Tuning Strategies for Enterprise SLMs

**Fine-tuning** techniques are crucial for optimizing open source SLMs for enterprise environments. Through fine-tuning, models can evolve from general sentence generators to **enterprise domain experts** or **assistants skilled in tool utilization**. The following fine-tuning strategies can be applied:

* **Conversation Grounding and Style Tuning**: To align models with enterprise knowledge and conversation styles, supervised learning is conducted using internal FAQ data, conversation logs, technical document Q\&A, etc. This guides models to answer based on accurate evidence and acquire company tone and manner. For example, in financial domains, tuning to use cautious expressions like "is expected to..." and in medical domains, training to provide advice mentioning sources without making hasty conclusions. Additionally, fine-tuning can include inappropriate response cases for compliance adherence to generate safe answers with profanity filters.
* **Tool Interface Fine-Tuning**: As discussed in prompting techniques, models can be fine-tuned to accurately follow specific API or function call formats. For example, learning to write "customer creation" requests in JSON format matching internal CRM system API specs. Specifically, creating simulation conversation data like CreateCustomer{"name": ..., "email": ...} for model training significantly increases probability of zero-shot function calls during actual operation.\[^2] Since LLMs have pre-learned function call sequences, developers can simply provide function names and JSON specs in system messages for models to properly fill and call functions. In our case too, injecting important internal tasks (e.g., report writing formats, workflow automation procedures) into model weights rather than Few-Shot examples saves runtime prompts and improves stability.
* **Knowledge Domain Fine-Tuning**: To create enterprise field-specialized models, additional training is conducted with relevant domain corpora. Law firms use case law texts, bio companies use papers for fine-tuning, enabling models to understand specialized terminology and concepts in those fields. This represents a prime example of utilizing OSS SLM advantages of easy customization. Fine-tuning enables models to reason appropriately for field contexts, achieving high accuracy and reliability difficult to obtain through user prompts alone.
* **Chain-of-Thought and Multi-Step Learning**: To improve complex reasoning or multi-agent collaboration planning, fine-tuning with data explaining problem-solving processes is possible. For example, learning math problems with solution processes together, or training with chain-of-thought records like "think this way then use that tool next" increases models' tendency to express intermediate thoughts while approaching problems. This improves agents' ability to self-plan and coordinate in multi-step tasks. However, such data preparation is challenging, so publicly available CoT datasets or Human-in-the-loop interaction logs are typically utilized.

Fine-tuning is powerful but not a universal key for all cases. It requires data preparation and costs, with risks of overfitting or internal confidential information leakage. Therefore, it should be used for precise tuning of only essential parts to maximize small model advantages. With lightweight fine-tuning technologies like LoRA achieving effects with minimal resources, companies can tune models while maintaining file-level confidentiality.

## References

* \[^1] [Raunak Jain (2024). _Fine-tuning LLMs for Enterprise RAG â€” A design perspective_](https://medium.com/@raunak-jain/fine-tuning-llms-for-enterprise-rag-8c1eb3ac6b32).
* \[^2] [Alice Moore (2025). _Fine-tune an LLM: Why, when, and how._](https://www.builder.io/blog/fine-tune-llm)

