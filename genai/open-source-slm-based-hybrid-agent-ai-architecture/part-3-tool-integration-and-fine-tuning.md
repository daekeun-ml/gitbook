---
description: 'Content Level: 200'
---

# Part 3: Tool Integration & Fine-Tuning

## Suggested Pre-Reading

* [Part 1: Overview & Background](part-1-overview-and-background.md)
* [Part 2: Agentic Patterns & Prompting](part-2-agentic-patterns-and-prompting.md)

## TL;DR

이 패턴은 SLM을 RAG/VectorDB, SQL 데이터베이스, 내부 API, 계산/코드 실행 도구와 통합하여 실용적인 작업을 수행합니다. 기업 환경에 최적화하기 위한 파인튜닝 전략에는 대화 스타일 조정, 도구 인터페이스 학습, 도메인별 지식 주입, 사고 연쇄 훈련이 포함됩니다. LoRA와 같은 경량 기법으로 효율적인 커스터마이징이 가능합니다.

## 1. Tool Integration Patterns with SLMs

기업 지식 탐색과 작업 자동화에 LLM을 활용하려면 외부 지식 소스와 소프트웨어 도구를 LLM 에이전트와 긴밀하게 연결하는 것이 필수적입니다. 이 아키텍처는 SLM 에이전트가 다양한 플러그인/도구를 사용하여 한계를 보완하도록 설계합니다. 대표적인 통합 패턴은 다음과 같습니다:

* **Search/RAG Integration**: RAG는 LLM에 최신의 신뢰할 수 있는 정보를 공급하는 표준 기법입니다. SLM 에이전트는 내부 문서 검색 엔진이나 벡터 DB와 연결하여 사용자 질문과 일치하는 문서를 검색하고 해당 내용을 사용하여 답변을 생성합니다. 예를 들어, "올해 2분기 매출 동향은 어떻습니까?"와 같은 질문이 도착하면 에이전트는 내부 보고서 DB를 쿼리하여 관련 단락을 검색하고 이를 기반으로 답변을 생성합니다. 검색된 문서는 답변과 함께 출처로 제시되어 증거 기반 응답을 보장합니다. RAG를 통해 SLM은 작은 파라미터로 방대한 지식 베이스에 접근할 수 있어 사실성에서 장점을 얻고 지속적으로 업데이트되는 정보를 반영할 수 있습니다. 그러나 잘못된 문서를 검색하거나 검색 결과를 무시하면 혼란을 야기할 수 있으므로, 앞서 논의한 RAG 최적화 파인튜닝은 SLM이 주어진 컨텍스트를 최대한 활용하고 모델 자체 지식보다 주입된 지식에 의존하도록 훈련합니다.
* **Table/SQL Agents**: 내부 데이터가 구조화된 DB나 스프레드시트에 존재할 때 에이전트는 TextToSQL 변환을 수행하고 DB에서 쿼리를 실행한 다음 결과에 대한 자연어 설명을 사용자에게 제공할 수 있습니다. 그러한 LLM SQL 에이전트는 비기술 사용자가 질문만으로 데이터를 쿼리할 수 있게 하여 생산성을 향상시킵니다. 많은 비즈니스 인텔리전스(BI) 시나리오가 실제로 TextToSQL 에이전트를 활용하며, 그러한 목적으로 SLM을 파인튜닝하거나 풍부한 프롬프트 예제를 제공하여 정확도를 향상시킬 수 있습니다. 그러나 SQL 에이전트를 사용할 때는 잘못된 쿼리가 데이터 품질에 영향을 주지 않도록 읽기 전용 권한을 사용하거나 Claude와 같은 상위 모델이 쿼리 결과를 검증하는 단계를 포함해야 합니다.
* **Internal API Integration**: LLM은 내부 웹 API나 자동화 스크립트에 연결하여 기업별 기능(예: 일정 생성, 티켓 발행, 이메일 발송)을 직접 수행할 수 있습니다. 예를 들어, 고객 챗봇이 사용자 요청에 따라 "주문 배송 주소 변경"을 해야 한다면 LLM이 내부 물류 시스템 API를 호출하는 명령을 생성하고 결과를 대화에 반영합니다. 에이전트 프레임워크(예: Strands, LangGraph, CrewAI, AutoGen)는 LLM이 정의된 JSON 형식으로 함수를 호출하고 응답을 처리할 수 있게 합니다. 예를 들어, SLM이 `SendEmail(to:"example@co.com", subject:"...", body:"...")`와 같은 함수를 생성하면 시스템이 실제 이메일을 발송한 다음 모델에게 결과를 알립니다("성공"). 그러한 내부 API 통합을 통해 LLM 에이전트는 단순한 답변을 넘어 실용적인 작업 실행 능력을 얻습니다. 이는 특히 반복적인 작업(티켓 처리, 양식 완성) 자동화나 LLM을 여러 시스템 간의 오케스트레이션 허브로 사용하는 것을 가능하게 합니다.
* **Calculation/Code Execution**: LLM이 쉽게 오류를 범하는 수학적 계산이나 코딩과 같은 작업에는 외부 계산기나 Python 실행기 도구를 연결하여 해결합니다. 예를 들어, "52의 제곱근은 무엇입니까?"와 같은 질문에 대해 에이전트는 `Calculator.calculate("sqrt(52)")`를 호출하고 결과로 응답합니다. 코딩 지원 에이전트의 경우 모델이 작성한 코드 스니펫을 즉시 실행하여 오류 메시지를 받아 수정할 수 있습니다. 그러한 자동 피드백 루프는 특히 소형 모델의 코딩 오류를 줄이는 데 효과적입니다.

위 패턴들의 통합을 통해 SLM 에이전트는 **풍부한 도구 생태계** 내에서 단순한 언어 응답을 넘어 **행동하는 AI**가 됩니다. 이는 독립형 LLM의 한계를 극복하고 기업 워크플로우에서 실제 활용하기 위한 필수 조건입니다. 중요한 고려사항으로는 **모델이 도구 정의와 사용법을 정확히 이해**하도록 보장하고 **오용에 대한 안전장치**를 구축하는 것입니다. 예를 들어, 도구 사용 전후에 Claude가 "이 호출이 적절합니까?"를 판단하거나 도구 결과 신뢰성을 평가하는 것입니다. 또한 각 통합 지점에서 로그를 유지하여 모델 행동을 모니터링하고 필요시 인간 검토를 받는 **Human-in-the-loop** 메커니즘을 고려해야 합니다.

## 2. Fine-Tuning Strategies for Enterprise SLMs

**파인튜닝** 기법은 기업 환경에 맞게 오픈소스 SLM을 최적화하는 데 중요합니다. 파인튜닝을 통해 모델은 일반적인 문장 생성기에서 **기업 도메인 전문가**나 **도구 활용에 숙련된 어시스턴트**로 진화할 수 있습니다. 다음과 같은 파인튜닝 전략을 적용할 수 있습니다:

* **Conversation Grounding and Style Tuning**: 모델을 기업 지식과 대화 스타일에 맞추기 위해 내부 FAQ 데이터, 대화 로그, 기술 문서 Q\&A 등을 사용하여 지도 학습을 수행합니다. 이는 모델이 정확한 증거를 바탕으로 답변하고 회사 톤과 매너를 습득하도록 안내합니다. 예를 들어, 금융 도메인에서는 "\~로 예상됩니다..."와 같은 신중한 표현을 사용하도록 튜닝하고, 의료 도메인에서는 성급한 결론 없이 출처를 언급하는 조언을 제공하도록 훈련합니다. 또한 파인튜닝에는 규정 준수를 위한 부적절한 응답 사례를 포함하여 욕설 필터와 함께 안전한 답변을 생성할 수 있습니다.
* **Tool Interface Fine-Tuning**: 프롬프팅 기법에서 논의한 바와 같이 모델을 특정 API나 함수 호출 형식을 정확히 따르도록 파인튜닝할 수 있습니다. 예를 들어, 내부 CRM 시스템 API 사양에 맞는 JSON 형식으로 "고객 생성" 요청을 작성하는 법을 학습합니다. 구체적으로 `CreateCustomer{"name": ..., "email": ...}`와 같은 시뮬레이션 대화 데이터를 생성하여 모델 훈련에 사용하면 실제 운영 중 제로샷 함수 호출 확률이 크게 증가합니다.\[2] LLM은 함수 호출 시퀀스를 사전 학습했으므로 개발자는 시스템 메시지에 함수 이름과 JSON 사양만 제공하면 모델이 적절히 채우고 함수를 호출할 수 있습니다. 우리의 경우에도 중요한 내부 작업(예: 보고서 작성 형식, 워크플로우 자동화 절차)을 퓨샷 예제가 아닌 모델 가중치에 주입하면 런타임 프롬프트를 절약하고 안정성을 향상시킵니다.
* **Knowledge Domain Fine-Tuning**: 기업 분야 전문화 모델을 만들기 위해 관련 도메인 코퍼스로 추가 훈련을 수행합니다. 법무법인은 판례법 텍스트를, 바이오 회사는 논문을 사용하여 파인튜닝하여 모델이 해당 분야의 전문 용어와 개념을 이해하도록 합니다. 이는 쉬운 커스터마이징이라는 OSS SLM 장점을 활용하는 대표적인 예입니다. 파인튜닝을 통해 모델이 분야 컨텍스트에 적절히 추론할 수 있게 하여 사용자 프롬프트만으로는 얻기 어려운 높은 정확도와 신뢰성을 달성합니다.
* **Chain-of-Thought and Multi-Step Learning**: 복잡한 추론이나 멀티 에이전트 협업 계획을 향상시키기 위해 문제 해결 과정을 설명하는 데이터로 파인튜닝할 수 있습니다. 예를 들어, 수학 문제를 해결 과정과 함께 학습하거나 "이렇게 생각한 다음 저 도구를 사용하세요"와 같은 사고 연쇄 기록으로 훈련하면 모델이 문제에 접근하면서 중간 생각을 표현하는 경향이 증가합니다. 이는 다단계 작업에서 에이전트의 자기 계획과 조정 능력을 향상시킵니다. 그러나 그러한 데이터 준비는 어려우므로 공개적으로 사용 가능한 CoT 데이터셋이나 Human-in-the-loop 상호작용 로그를 일반적으로 활용합니다.

파인튜닝은 강력하지만 모든 경우에 만능 열쇠는 아닙니다. 데이터 준비와 비용이 필요하며 과적합이나 내부 기밀 정보 유출 위험이 있습니다. 따라서 소형 모델의 장점을 극대화하기 위해 필수적인 부분만 정밀하게 튜닝하는 데 사용해야 합니다. LoRA와 같은 경량 파인튜닝 기술로 최소한의 리소스로 효과를 달성할 수 있어 기업이 파일 수준 기밀성을 유지하면서 모델을 튜닝할 수 있습니다.

## References

* \[1] [Raunak Jain (2024). _Fine-tuning LLMs for Enterprise RAG — A design perspective_](https://medium.com/@raunak-jain/fine-tuning-llms-for-enterprise-rag-8c1eb3ac6b32).
* \[2] [Alice Moore (2025). _Fine-tune an LLM: Why, when, and how._](https://www.builder.io/blog/fine-tune-llm)

