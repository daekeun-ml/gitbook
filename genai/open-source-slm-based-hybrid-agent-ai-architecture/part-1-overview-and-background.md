# Part 1: Overview & Background

#### Content Level: 200

## TL;DR

We describe a hybrid AI architecture using open source SLMs as primary agents with proprietary LLMs like Claude as backup. SLMs handle most tasks for cost efficiency, escalating to Claude when confidence is low or queries are complex. Claude performs meta-tasks like planning, query rewriting, and verification. The series covers multi-agent workflows, fine-tuning strategies for enterprise use, and evaluates trade-offs between open source and commercial models.

### 1. Background

Recently, lightweight open source language models under 10B parameters have increasingly shown competitive performance compared to closed large models. SLMs from Meta LLaMA family, Microsoft Phi family, Alibaba Qwen family, etc., demonstrate generation performance comparable to large LLMs in some benchmarks through quality prompt injection and fine-tuning. For example, one study evaluating 9 different SLMs showed that SLMs could match the quality of OpenAI GPT-4-based implementations while providing higher response latency consistency and significantly reduced costs.\[^1] In actual production environment applications, adopting open source SLMs has been reported to maintain response quality while stabilizing latency and reducing costs by **more than 5 times**. Conversely, while closed LLMs like GPT-4 and Claude still excel in general reasoning capabilities and multi-turn conversation understanding, they have accumulated API usage costs, risks of latency variations or temporary service interruptions, and are difficult to customize. Cloud API approaches are particularly unstable during traffic peaks, with per-token charges accumulating to create cost burdens for startups and large enterprises during large-scale usage, and limitations in domain adaptability due to inability to modify model internals or perform fine-tuning with company data.

In enterprise contexts, data privacy and regulatory compliance are also important when utilizing LLMs for sensitive internal data or knowledge-based Q\&A. Open source SLMs can be deployed on-premises on proprietary infrastructure, allowing use without risk of internal data leakage while securing transparency and control over model weights and behavior. Due to these advantages, companies are exploring hybrid strategies that utilize customized lightweight models optimized for specific tasks while relying on large proprietary models when general high-difficulty reasoning is needed.

### 2. SLM/LLM Hybrid Architecture Overview

<figure><img src="../../.gitbook/assets/slm_llm_hybrid_part1.png" alt=""><figcaption></figcaption></figure>

_Figure 1. SLM/LLM Hybrid AI Architecture_

The core components of this hybrid architecture consist of open source SLMs, proprietary LLMs (e.g., Claude), and knowledge/tool plugins. The typical operational flow is as follows:

* **General Query Processing**: When user queries arrive, the primary SLM agent first attempts to process them. This primary agent is a pre-fine-tuned LLaMA family, Phi family, Qwen family, etc., that has learned enterprise domain knowledge and tool usage, capable of independently constructing answers for simple or clear questions. When necessary, it calls related knowledge search tools (e.g., internal document search, vector DB queries) to retrieve supporting information and generate evidence-based responses.
* **Query Difficulty/Ambiguity Assessment and Fallback**: When the SLM agent finds it difficult to create answers or lacks confidence (e.g., queries are ambiguous requiring additional clarification, lack of external knowledge, tool usage errors), it escalates to the superior model Claude. The SLM itself signals such judgments or Claude calls are determined according to predefined failure detection rules. Claude re-analyzes queries to perform detailed planning, question restructuring, or temporary answer generation. Subsequently, SLM agents receive Claude's output (e.g., refined questions or plans) to continue follow-up tasks. Thus Claude functions as a planner and quality manager rather than directly generating final answers, intervening only minimally as needed.
* **Multi-Agent Collaboration and Result Integration**: For complex requests, Claude (or superior orchestrator) divides queries into multiple sub-tasks and creates and routes SLM sub-agents to perform each in parallel or sequentially. For example, for research questions, the lead agent plans topics to investigate then executes multiple search agents in parallel to web search/document search different keywords each. Each sub-agent independently utilizes its context window to summarize/analyze search results and produce partial answers, then returns these to the lead agent. The lead agent or separate combining agent merges and organizes these intermediate results to construct final answers. All claims include evidence sources provided by each sub-agent to enhance reliability.
* **Claude Verification and Final Answer Generation**: Finally, in important cases, Claude reviews the final combined answer once more to check for factual errors or inappropriate parts. Similarly to Anthropic's multi-Claude agent system, a separate LLM reviewer verified factual accuracy, source matching, content omissions, etc., scoring 0-1 before sending final answers to users. If necessary, Claude makes revision suggestions or instructs SLM agents to retry, with only answers passing all verification delivered to users.

The hybrid agent architecture fundamentally leverages the fast responsiveness and flexible customization capabilities of lightweight SLMs while **borrowing higher-order reasoning power** from superior models only when needed. The following sections examine representative design patterns.

### 3. Open vs. Closed Models: Trade-Offs and Discussion

When building hybrid agent architectures, how to distribute open source SLMs and commercial large LLMs is a matter of **technical/strategic trade-offs**. Key comparison factors include:

* **Performance**: Closed top-tier models like Claude still lead in broad general knowledge, reasoning capabilities, and multilingual processing. Larger models show strengths in complex instructions and creative generation. Conversely, open SLMs have higher error probability in high-difficulty reasoning due to size limitations, but can match or exceed large models when limited to specific tasks. Particularly in domain-specific or RAG situations, well-tuned SLMs sometimes provide more accurate and faster answers than giant models. In summary, large models dominate without tuning, but small models can excel in their fields with tuning/customization.
* **Cost and Infrastructure**: Open models have initial setup costs (model hosting servers, etc.) but near-zero per-use costs. Conversely, API models have linearly increasing costs with call volume. For large-scale services, open models are much more economical long-term. Additionally, deploying on proprietary infrastructure enables operation on internal networks without internet connections, potentially achieving lower latency without network round-trips. However, enterprises must bear MLOps burdens like infrastructure management and model upgrades, with larger models increasing these burdens. Meanwhile, models like Claude provide transparent scaling management in cloud environments, offering high development convenience. Our hybrid approach optimizes cost-effectiveness by processing general requests with local SLMs for cost reduction while supplementing performance with occasional Claude API calls.
* **Data Privacy and Control**: Open models have transparent model weights and inference paths, enabling tracking of output reasoning or controlling learned content. Additionally, all inference occurs internally, eliminating need to transmit sensitive data externally. This is a very important advantage in strictly regulated industries like finance and healthcare, where on-premises LLMs can satisfy sensitive information protection and compliance requirements. Conversely, using cloud LLMs transmits input data to third parties with potential information retention in models. Many companies consider open model adoption for this reason. Open models also allow adjusting filtering levels or correcting bias according to internal policies, while commercial model filtering/censorship must follow provider policies. Therefore, open source gains weight when regulatory environments or proprietary security requirements are important.
* **Adaptability and Innovation Speed**: Open ecosystem models are developing daily, with latest public models like GPT-OSS, Qwen3, LLaMA 4 already achieving GPT-4o levels according to evaluations. Community efforts produce quality tuning methods and extension tools with rapid improvement cycles. From enterprise perspectives, adopting open models enables immediate utilization of such innovations or adding desired features through proprietary contributions. Conversely, closed models require waiting for providers to release new versions, with low autonomy in problem-solving or feature addition due to unknown internal operations. In other words, customization freedom is far superior with open models. However, commercial models have professional research teams continuously tuning, so latest features are introduced first and may be more efficient to purchase and use compared to open models.
* **Safety and Alignment**: Proprietary LLM models like Anthropic Claude and OpenAI GPT undergo extensive RLHF for high reliability in suppressing harmful speech, following commands without questioning, fact-checking, etc. Open models have relatively fewer RLHF training stages, requiring developers to supplement these aspects under their responsibility. Without proper handling, small models may generate sensitive information or inappropriate responses without filters. Therefore, when using open models, separate model output monitoring or safety mechanisms (e.g., profanity filters, LLM-based secondary censorship) must be implemented in parallel. In hybrid systems, this problem can be mitigated by having proprietary LLMs censor/refine final responses. For example, having Claude inspect SLM answers for "company policy-inappropriate content" and removing or rewriting such parts. Through such collaboration, open model strengths can be preserved while utilizing commercial model safety mechanisms.

In summary, **open vs closed** choice represents a balance of **control/flexibility vs immediacy/performance**. Our hybrid architecture harmonizes these two worlds, implementing the principle of "**usually fast and cheap with open models, deep and accurate with large models only when needed**." This is an approach satisfying enterprise desires for **cost efficiency**, **scalability**, and **reliability**. Customer cases applying such multi-model strategies and dramatically reducing **LLM usage costs** while maintaining or improving user satisfaction are increasing.

## Further Reading

* [Part 2: Agentic Patterns & Prompting](part-2-agentic-patterns-and-prompting.md)
* [Part 3: Tool Integration & Fine-Tuning](part-3-tool-integration-and-fine-tuning.md)

## References

* \[^1] [S. S. et al. (2024). _Scaling Down to Scale Up: Replacing OpenAI's LLM with Open Source SLMs in Production_.](https://arxiv.org/abs/2312.14972)
