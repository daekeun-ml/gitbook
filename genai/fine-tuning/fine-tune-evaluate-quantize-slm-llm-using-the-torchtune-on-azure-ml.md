# Fine-tune/Evaluate/Quantize SLM/LLM using the torchtune on Azure ML

> _ì´ ê¸€ì€ ì €ìê°€ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ë¨¸ì‹  ëŸ¬ë‹ ë¸”ë¡œê·¸ì— ê¸°ê³ í•œ_ [_Fine-tune/Evaluate/Quantize SLM/LLM using the torchtune on Azure ML_](https://techcommunity.microsoft.com/blog/machinelearningblog/fine-tuneevaluatequantize-slmllm-using-the-torchtune-on-azure-ml/4285663)_ì„ ì§ì ‘ í•œêµ­ì–´ë¡œ ë²ˆì—­ ë° í¸ì§‘í•˜ì˜€ìŠµë‹ˆë‹¤._

Azure MLì—ì„œ torchtuneì„ í™œìš©í•´ ì†Œí˜• ë° ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(SLM/LLM)ì„ íš¨ê³¼ì ìœ¼ë¡œ íŒŒì¸ íŠœë‹í•˜ê³  í‰ê°€í•˜ë©° ì–‘ìí™” í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•œ ìˆ˜ìš”ê°€ ì¦ê°€í•¨ì— ë”°ë¼ íŒŒì¸ íŠœë‹ ë° ìµœì í™”ë¥¼ ë” ì‰½ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ê²¬ê³ í•œ íˆ´í‚·ì´ í•„ìš”í•©ë‹ˆë‹¤. torchtuneì€ ë¶„ì‚° í›ˆë ¨, ìœ ì—°í•œ ë¡œê¹…, í‰ê°€, ëª¨ë¸ ì–‘ìí™”ì˜ ì¼ë ¨ì˜ ê³¼ì •ì„ ì‰½ê²Œ ìˆ˜í–‰í•˜ê²Œ ë„ì™€ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. Azure MLì€ í™•ì¥ ê°€ëŠ¥í•œ ì¸í”„ë¼ ë° í†µí•© ì˜µì…˜ì„ ì œê³µí•˜ì—¬ torchtuneì„ ë³´ì™„í•˜ë¯€ë¡œ SLM/LLMì„ ì‹¤í—˜í•˜ê³  ë°°í¬í•˜ëŠ” ë° ì´ìƒì ì¸ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

ë³¸ ê°€ì´ë“œì—ì„œëŠ” ë‹¤ìŒì„ ìœ„í•œ ì‹¤ìŠµ ì½”ë“œ ì˜ˆì œì™€ ë‹¨ê³„ë³„ ì§€ì¹¨ì„ ì œê³µí•©ë‹ˆë‹¤.

* íŒŒì¸ íŠœë‹ ë° ë¶„ì‚° í›ˆë ¨ì„ ìœ„í•œ Azure ML ì„¤ì • ë° torchtune ì—°ë™ ë°©ë²•
* Azure Blob Storage ë§ˆìš´íŠ¸ í™˜ê²½ì—ì„œ YAML ë ˆì‹œí”¼ì˜ ë™ì  ê²½ë¡œ ì¡°ì • ì²˜ë¦¬ ë°©ë²•
* ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ê°€ ì œí•œëœ ë””ë°”ì´ìŠ¤ì— ë°°í¬í•˜ê¸° ìœ„í•´ ëª¨ë¸ì„ ìµœì í™”í•˜ëŠ” ì–‘ìí™” ì ìš© ë°©ë²•

ì´ ê°€ì´ë“œë¥¼ ë§ˆì¹˜ë©´ ì—¬ëŸ¬ë¶„ì€ torchtuneê³¼ Azure MLì„ í™œìš©í•´ í™•ì¥ ê°€ëŠ¥í•˜ê³  íš¨ìœ¨ì ì¸ SLM/LLM íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³ , ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ì ‘ê·¼ì„±ì„ ë†’ì´ëŠ” ë°©ë²•ì„ ìµíˆê²Œ ë©ë‹ˆë‹¤.

#### ğŸ”¥ í•¸**ì¦ˆì˜¨ë©:** [**https://github.com/Azure/torchtune-azureml**](https://github.com/Azure/torchtune-azureml) <a href="#id-7dbf" id="id-7dbf"></a>

## 1. ê°œìš” <a href="#id-3885" id="id-3885"></a>

***

### 1.1. torchtune <a href="#id-3885" id="id-3885"></a>

torchtuneì€ SLM/LLM ëª¨ë¸ì„ ì†ì‰½ê²Œ íŒŒì¸ íŠœë‹í•˜ë„ë¡ ì„¤ê³„ëœ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. torchtuneì€ ë‹¨ìˆœì„±ê³¼ ìœ ì—°ì„±ì´ ë›°ì–´ë‚˜ë©°, ì‚¬ìš©ìëŠ” YAML ê¸°ë°˜ ë ˆì‹œí”¼ë¥¼ í†µí•´ ìµœì†Œí•œì˜ ì½”ë“œë¡œ íŒŒì¸ íŠœë‹, í‰ê°€ ë° ì–‘ìí™”ë¥¼ ì†ì‰½ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìëŠ” êµ¬ì¡°í™”ë˜ê³  ê°€ë…ì„±ì´ ë†’ì€ YAML í¬ë§·ìœ¼ë¡œ ë³µì¡í•œ í›ˆë ¨ ì„¤ì •ì„ êµ¬ì„±ì„ ì •ì˜í•˜ê³  ì¡°ì •í•  ìˆ˜ ìˆê¸°ì—, í›ˆë ¨ ì½”ë“œë¥¼ ì¼ì¼ì´ ì‘ì„±í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. torchtuneì€ YAML ë ˆì‹œí”¼ ê¸°ë°˜ ì„¤ì • íŒŒì¼ë¡œ ì‹¤í—˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°€ì†í™”í•˜ê³  ë‹¤ì–‘í•œ ëª¨ë¸ê³¼ ì‘ì—…ì—ì„œ ì„¤ì • íŒŒì¼ì„ ì‰½ê²Œ ë³µì œí•˜ê±°ë‚˜ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ ë°©ì‹ì€ íŒŒì¸ íŠœë‹ì—ì„œ ëª¨ë¸ ë°°í¬ê¹Œì§€ì˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°„ì†Œí™”í•˜ëŠ”ë° ì´ìƒì ì…ë‹ˆë‹¤.

* **ì†ì‰¬ìš´ ëª¨ë¸ íŠœë‹**: torchtuneì€ SLM íŒŒì¸ íŠœë‹ ê³¼ì •ì„ ê°„ì†Œí™”í•˜ëŠ” PyTorch ë„¤ì´í‹°ë¸Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, AI ì „ë¬¸ ì§€ì‹ì´ ì—†ëŠ” ì‚¬ìš©ìë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ë¶„ì‚° í›ˆë ¨ì˜ ê°„í¸í•œ ì ìš©**: torchtuneì€ ë¶„ì‚° í›ˆë ¨ì„ ìœ„í•œ ì„¤ì •ì„ ê°„ì†Œí™”í•˜ì—¬ ì‚¬ìš©ìê°€ ìµœì†Œí•œì˜ êµ¬ì„±ìœ¼ë¡œ ë‹¤ì¤‘ GPUì— ê±¸ì³ ëª¨ë¸ì„ í™•ì¥í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ì‚¬ìš©ìì˜ ì‹œí–‰ì°©ì˜¤ë¥¼ í¬ê²Œ ì¤„ì—¬ì¤ë‹ˆë‹¤.
* **ê°„ì†Œí™”ëœ ëª¨ë¸ í‰ê°€ ë° ì–‘ìí™”**: torchtuneì€ ëª¨ë¸ í‰ê°€ ë° ì–‘ìí™”ë¥¼ ê°„ì†Œí™”í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ ì‰½ê²Œ í‰ê°€í•˜ê³  ë°°í¬ë¥¼ ìœ„í•´ ëª¨ë¸ì„ ìµœì í™”í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
* **í™•ì¥ì„± ë° ì´ì‹ì„±**: torchtuneì€ ë‹¤ì–‘í•œ í´ë¼ìš°ë“œ í”Œë«í¼ê³¼ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ë§Œí¼ ìœ ì—°í•˜ë©°, Azure MLê³¼ ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

torchtuneì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ê³µì‹ ì‚¬ì´íŠ¸](https://pytorch.org/torchtune/stable/index.html)ë¥¼ ì°¸ì¡° ë°”ëë‹ˆë‹¤.

### 1.2. Azure MLì— torchtune ì—°ë™ <a href="#id-994e" id="id-994e"></a>

<figure><img src="https://miro.medium.com/v2/resize:fit:1400/1*TOde_oPu6N25evfCM5bz7Q.png" alt="" height="297" width="700"><figcaption></figcaption></figure>

Azure MLì—ì„œ torchtune ì‹¤í–‰ ì‹œ GenAI ì›Œí¬í”Œë¡œë¥¼ ê°„ì†Œí™”í•˜ëŠ” ëª‡ ê°€ì§€ ì´ì ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

* **í™•ì¥ì„± ë° ì»´í“¨íŒ… ì„±ëŠ¥**: Azure MLì€ ê°•ë ¥í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•˜ê¸°ì— torchtuneì´ ë©€í‹° GPU ë˜ëŠ” ë¶„ì‚° í´ëŸ¬ìŠ¤í„°ì—ì„œ ë‹¤ì¤‘ SLM/LLMì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ëŒ€ê·œëª¨ ë°ì´í„° ì„¸íŠ¸ì—ì„œ íŒŒì¸ íŠœë‹ ë° ì–‘ìí™”ì™€ ê°™ì€ ì§‘ì•½ì ì¸ ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë° ì´ìƒì ì…ë‹ˆë‹¤.
* **ê´€ë¦¬í˜• ML í™˜ê²½**: Azure MLì€ ì™„ì „ ê´€ë¦¬í˜• í™˜ê²½ì„ ì œê³µí•˜ë¯€ë¡œ ì¢…ì†ì„± ì„¤ì • ë° ë²„ì „ ê´€ë¦¬ê°€ ìš©ì´í•©ë‹ˆë‹¤. torchtuneì„ ìœ„í•œ ì„¤ì • ì‹œê°„ì´ ë‹¨ì¶•ë˜ë¯€ë¡œ ì‚¬ìš©ìëŠ” ì¸í”„ë¼ ì„¤ì •ì— ëŒ€í•œ ë¶€ë‹´ ì—†ì´ ëª¨ë¸ ìµœì í™”ì— ì§‘ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ëª¨ë¸ ë°°í¬ ë° í™•ì¥**: Azure MLì€ Azureì˜ í´ë¼ìš°ë“œ ì¸í”„ë¼ì— ë°°í¬í•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ê²½ë¡œë¥¼ ì œê³µí•˜ì—¬ ê°•ë ¥í•œ ëª¨ë‹ˆí„°ë§ ë° í™•ì¥ ê¸°ëŠ¥ìœ¼ë¡œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í”„ë¡œë•ì…˜ìœ¼ë¡œ ì‰½ê²Œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **íƒ€ Azure ì„œë¹„ìŠ¤ì™€ì˜ ì›í™œí•œ í†µí•©**: ì‚¬ìš©ìëŠ” ë°ì´í„° ì„¸íŠ¸ ì €ì¥ì„ ìœ„í•œ Azure Blob Storage ë˜ëŠ” ë°ì´í„° ê´€ë¦¬ë¥¼ ìœ„í•œ Azure SQLê³¼ ê°™ì€ ë‹¤ë¥¸ Azure ì„œë¹„ìŠ¤ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìƒíƒœê³„ ì§€ì›ìœ¼ë¡œ ì›Œí¬í”Œë¡œ íš¨ìœ¨ì„±ì´ í–¥ìƒë˜ë¯€ë¡œ AzureMLì€ torchtune ê¸°ë°˜ ëª¨ë¸ íŠœë‹ ë° ë°°í¬ë¥¼ ìœ„í•œ ê°•ë ¥í•œ ì„¤ë£¨ì…˜ì´ ë©ë‹ˆë‹¤.

## 2. torchtune YAML ì„¤ì • <a href="#id-457e" id="id-457e"></a>

***

torchtune YAML êµ¬ì„±ì—ì„œ ê° ë§¤ê°œë³€ìˆ˜ì™€ ì„¤ì •ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ íŒŒì¸ íŠœë‹í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ í•™ìŠµ ë°©ì‹ì„ ì œì–´í•©ë‹ˆë‹¤. ë‹¤ìŒì€ SFT (Supervised Fine-Tuning; ì§€ë„ íŒŒì¸ íŠœë‹), DPO (Direct Preference Optimization; ì§ì ‘ ì„ í˜¸ë„ ìµœì í™”), KD (Knowledge Distillation; ì§€ì‹ ì¦ë¥˜), í‰ê°€, ì–‘ìí™”ì™€ ê°™ì€ ì£¼ìš” êµ¬ì„± ìš”ì†Œì— ëŒ€í•œ ì„¸ë¶€ ì •ë³´ì…ë‹ˆë‹¤.

* **SFT (Supervised Fine-Tuning)**: ì´ ì„¤ì •ì€ ë ˆì´ë¸”ë§ëœ ë°ì´í„° ì„¸íŠ¸ë¡œ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ë°ì´í„° ì„¸íŠ¸ ê²½ë¡œ, ë°°ì¹˜ í¬ê¸°, í•™ìŠµ ì†ë„ ë° ì—í¬í¬ ìˆ˜ë¥¼ ì§€ì •í•˜ëŠ” ê²ƒì´ í¬í•¨ë©ë‹ˆë‹¤. SFTëŠ” ë ˆì´ë¸” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ íŠœë‹í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.
* **DPO (Direct Preference Optimization)**: ì´ ì„¤ì •ì€ ì‚¬ëŒì˜ ì„ í˜¸ë„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë³´ìƒ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¬¼ì˜ ìˆœìœ„ë¥¼ ë§¤ê¸°ê³ , ì„ í˜¸í•˜ëŠ” ì‘ë‹µì— ëŒ€í•´ ëª¨ë¸ì´ ì§ì ‘ ìµœì í™”í•˜ë„ë¡ ì•ˆë‚´í•©ë‹ˆë‹¤.
* **KD (Knowledge Distillation)**: ì´ ì„¤ì •ì—ì„œëŠ” ë” í¬ê³  ë” ì •í™•í•œ ëª¨ë¸(êµì‚¬)ì´ ë” ì‘ì€ ëª¨ë¸(í•™ìƒ)ì—ê²Œ ì§€ì‹ì„ ì „ë‹¬í•©ë‹ˆë‹¤. YAML ì„¤ì •ì€ êµì‚¬ ë° í•™ìƒ ëª¨ë¸ ê²½ë¡œ, temperature (í™•ë¥  í‰í™œí™”ìš©), alpha (êµì‚¬ ì˜ˆì¸¡ê³¼ ë ˆì´ë¸” ê°„ì˜ ì†ì‹¤ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•œ ê°€ì¤‘ì¹˜)ë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. KDë¥¼ ì‚¬ìš©í•˜ë©´ ì‘ì€ ëª¨ë¸ì´ í° ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ëª¨ë°©í•˜ë©´ì„œ ê³„ì‚° ìš”êµ¬ ì‚¬í•­ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **í‰ê°€ (Evaluation)**: torchtuneì€ EleutherAIì˜ LM í‰ê°€ Harnessì™€ ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ TruthfulQAì™€ ê°™ì€ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì§„ì‹¤ì„±ê³¼ ì •í™•ì„±ì„ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ì–‘ìí™”**: ì´ ì„¤ì •ì€ ëª¨ë¸ ê°€ì¤‘ì¹˜ì˜ ë¹„íŠ¸ ì •ë°€ë„ë¥¼ ë‚®ì¶° ëª¨ë¸ í¬ê¸°ì™€ ê³„ì‚° ìš”êµ¬ ì‚¬í•­ì„ ì¤„ì…ë‹ˆë‹¤. YAML ì„¤ì • íŒŒì¼ì„ í†µí•´ ì–‘ìí™” ë°©ë²•(ì˜ˆ: 8ë¹„íŠ¸ ë˜ëŠ” 4ë¹„íŠ¸), ëŒ€ìƒ ë ˆì´ì–´, ê·¸ë¦¬ê³  ì•„ë§ˆë„ í›ˆë ¨ í›„ ì–‘ìí™”ë¥¼ ìœ„í•œ ì¶”ê°€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì´ëŠ” ë¦¬ì†ŒìŠ¤ê°€ ì œí•œëœ ì—ì§€ ë””ë°”ì´ìŠ¤ì— ëª¨ë¸ì„ ë°°í¬í•˜ëŠ” ë° íŠ¹íˆ ìœ ìš©í•©ë‹ˆë‹¤.

torchtuneì€ ì½”ë“œë¥¼ ì‘ì„±í•˜ì§€ ì•Šê³ ë„ YAML íŒŒì¼ ì„¤ì •ë§Œìœ¼ë¡œ ìœ„ì˜ ë ˆì‹œí”¼ë“¤ì„ ì‰½ê²Œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [torchtune ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://github.com/pytorch/torchtune)ì—ì„œ YAML ìƒ˜í”Œë“¤ì„ í™•ì¸í•˜ê¸° ë°”ëë‹ˆë‹¤.

## 3. Azure ML í›ˆë ¨ ê¿€íŒ <a href="#faf3" id="faf3"></a>

***

Azure MLì— torchtuneì˜ ë…ë¦½ ì‹¤í–‰í˜•(standalone) ëª…ë ¹ì„ ì ìš©í•˜ëŠ” ê²ƒì€ ë§¤ìš° ê°„ë‹¨í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì•„í‚¤í…ì²˜ì— í‘œí˜„ëœ ëŒ€ë¡œ í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ-íŒŒì¸ íŠœë‹-í‰ê°€-ì–‘ìí™” íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•˜ë ¤ë©´ ì‹œí–‰ì°©ì˜¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì•„ë˜ì˜ ê¿€íŒì„ ì°¸ì¡°í•˜ì—¬ ì—¬ëŸ¬ë¶„ì˜ ì›Œí¬ë¡œë“œì— ì ìš©í•  ë•Œ ì‹œí–‰ì°©ì˜¤ë¥¼ ìµœì†Œí™”í•˜ì„¸ìš”.

### **3.1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ** <a href="#id-89bb" id="id-89bb"></a>

`torch_distributed_zero_first` ë°ì½”ë ˆì´í„°(decorator)ëŠ” ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤(ì¼ë°˜ì ìœ¼ë¡œ ë¶„ì‚° ì„¤ì •ì—ì„œ rank 0)ë§Œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ë¡œë“œì™€ ê°™ì€ íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤ê°€ ë™ì‹œì— ëª¨ë¸ì„ ë¡œë“œí•˜ë ¤ê³  ì‹œë„í•˜ì—¬ ì¤‘ë³µ ë‹¤ìš´ë¡œë“œ, ê³¼ë„í•œ ë©”ëª¨ë¦¬ ì‚¬ìš© ë˜ëŠ” ì¶©ëŒì´ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¶„ì‚° í™˜ê²½ì—ì„œ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

`torch_distributed_zero_first`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•˜ëŠ” ì´ìœ ë¥¼ ëª‡ ê°€ì§€ ë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.

1. **ì¤‘ë³µ ë‹¤ìš´ë¡œë“œ ë°©ì§€**: ë¶„ì‚° ì„¤ì •ì—ì„œ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ë™ì‹œì— ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ë ¤ê³  í•˜ë©´ ë¶ˆí•„ìš”í•œ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ê³¼ ì¤‘ë³µ íŒŒì¼ ì €ì¥ì†Œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `torch_distributed_zero_first`ëŠ” í•˜ë‚˜ì˜ í”„ë¡œì„¸ìŠ¤ë§Œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ë„ë¡ í•˜ì—¬ ì´ëŸ¬í•œ ì¤‘ë³µì„ ë°©ì§€í•©ë‹ˆë‹¤.
2. **ì¶©ëŒ ë° íŒŒì¼ ì†ìƒ ë°©ì§€**: ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤ê°€ ë‹¤ìš´ë¡œë“œ ì¤‘ì— ë™ì¼í•œ íŒŒì¼ì„ ì“°ê±°ë‚˜ ìˆ˜ì •í•˜ë ¤ê³  í•˜ë©´ íŒŒì¼ ì†ìƒ ë˜ëŠ” ì•¡ì„¸ìŠ¤ ì¶©ëŒì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `torch_distributed_zero_first`ëŠ” í•˜ë‚˜ì˜ í”„ë¡œì„¸ìŠ¤ë§Œ íŒŒì¼ ë‹¤ìš´ë¡œë“œë¥¼ ì²˜ë¦¬í•˜ë„ë¡ í—ˆìš©í•˜ì—¬ ì´ëŸ¬í•œ ìœ„í—˜ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.

ë‹¤ìš´ë¡œë“œê°€ ì™„ë£Œëœ ëª¨ë¸ì€ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ì— ê±¸ì³ ë¶„ì‚°ë˜ê±°ë‚˜ ë©”ëª¨ë¦¬ì— ë¡œë“œë©ë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ ë‹¤ì¤‘ í”„ë¡œì„¸ìŠ¤ í™˜ê²½ì—ì„œ ëª¨ë¸ ë¡œë”© í”„ë¡œì„¸ìŠ¤ë¥¼ ë³´ë‹¤ íš¨ìœ¨ì ì´ê³  ì•ˆì •ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.

### 3.2. í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ ì¢…ë£Œ <a href="#dc84" id="dc84"></a>

torchtuneì˜ CLIë¡œ Azure MLì— ë¶„ì‚° í›ˆë ¨ì„ ì ìš©í•  ë•ŒëŠ” í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì„ ì‹ ì¤‘í•˜ê²Œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. torchtune CLI(Command Line Interface)ì˜ ë¶„ì‚° í›ˆë ¨ ë ˆì‹œí”¼ëŠ” `dist.init_process_group(â€¦`)ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì´ ì´ë¯¸ í™œì„±í™”ëœ ê²½ìš° ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì„ ì´ˆê¸°í™”í•˜ë©´ ì¶©ëŒì´ ë°œìƒí•˜ì—¬ ì¤‘ì²©ë˜ê±°ë‚˜ ì¤‘ë³µëœ í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì´ ë°œìƒí•˜ê²Œ ë©ë‹ˆë‹¤.

ì´ë¥¼ ë°©ì§€í•˜ë ¤ë©´ torchtuneì˜ ë¶„ì‚° í›ˆë ¨ì´ ì‹œì‘ë˜ê¸° ì „ì— ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì„ ëª¨ë‘ ì¢…ë£Œí•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” `dist.destroy_process_group(â€¦)`ì„ í˜¸ì¶œí•˜ì—¬ í™œì„± í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ì„ ì¢…ë£Œí•˜ì—¬ ê¹¨ë—í•œ ìƒíƒœë¥¼ ìœ ì§€í•¨ìœ¼ë¡œì¨ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ í”„ë¡œì„¸ìŠ¤ ì¶©ëŒì„ ë°©ì§€í•˜ì—¬ ê¸°ì¡´ ê·¸ë£¹ê³¼ ê²¹ì¹˜ì§€ ì•Šê³  torchtune CLIì˜ ë¶„ì‚° í›ˆë ¨ ë ˆì‹œí”¼ê°€ ì›í™œí•˜ê²Œ ì‘ë™í•˜ê²Œ ë©ë‹ˆë‹¤. 3.1ì ˆê³¼ 3.2ì ˆì˜ ì½”ë“œ ìŠ¤ë‹ˆí«ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```python
MASTER_ADDR = os.environ.get('MASTER_ADDR', '127.0.0.1')
MASTER_PORT = os.environ.get('MASTER_PORT', '7777')
WORLD_SIZE = int(os.environ.get("WORLD_SIZE", 1))
GLOBAL_RANK = int(os.environ.get('RANK', -1))
LOCAL_RANK = int(os.environ.get('LOCAL_RANK', -1))

NUM_GPUS_PER_NODE = torch.cuda.device_count()
NUM_NODES = WORLD_SIZE // NUM_GPUS_PER_NODE

if LOCAL_RANK != -1:
    dist.init_process_group(backend="nccl" if dist.is_nccl_available() else "gloo")

@contextmanager
def torch_distributed_zero_first(local_rank: int):
    """
    Decorator to make all processes in distributed training
    wait for each local_master to do something.
    """
    if local_rank not in [-1, 0]:
        dist.barrier(device_ids=[local_rank])
    yield
    if local_rank == 0:
        dist.barrier(device_ids=[0])
        
...

with torch_distributed_zero_first(LOCAL_RANK):        
    # Download the model
    download_model(args.teacher_model_id, args.teacher_model_dir)
    download_model(args.student_model_id, args.student_model_dir)

# Construct the fine-tuning command
if "single" in args.tune_recipe:
    print("***** Single Device Training *****");
    full_command = (
        f'tune run '
        f'{args.tune_recipe} '
        f'--config {args.tune_config_name}'
    )
    # Run the fine-tuning command
    run_command(full_command)
else:
    print("***** Distributed Training *****");        

    dist.destroy_process_group()
    if GLOBAL_RANK in {-1, 0}:
        # Run the fine-tuning command
        full_command = (
            f'tune run --master-addr {MASTER_ADDR} --master-port {MASTER_PORT} --nnodes {NUM_NODES} --nproc_per_node {NUM_GPUS_PER_NODE} '
            f'{args.tune_recipe} '
            f'--config {args.tune_config_name}'
        )            
        run_command(full_command)
...and more...
```

### 3.3. ë™ì  ì„¤ì • (Dynamic Configuration) <a href="#id-64d4" id="id-64d4"></a>

ì»´í“¨íŒ… í´ëŸ¬ìŠ¤í„°ì— ë§ˆìš´íŠ¸ëœ Azure Blob ìŠ¤í† ë¦¬ì§€ì˜ ê²½ë¡œëŠ” ë™ì ì´ë¯€ë¡œ, YAML ë ˆì‹œí”¼ëŠ” ë™ì ìœ¼ë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒì€ Jinja í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ì„¤ì • íŒŒì¼ì„ ì¡°ì •í•˜ì—¬ ëŸ°íƒ€ì„ì— ê²½ë¡œê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ë„ë¡ í•˜ëŠ” ë°©ë²•ì˜ í•œ ì˜ˆì‹œì…ë‹ˆë‹¤.

```yaml
# Dynamically modify fine-tuning YAML file.
import os, jinja2
jinja_env = jinja2.Environment()  
    
template = jinja_env.from_string(Path(args.tune_config_name).open().read())
train_path = os.path.join(args.train_dir, "train.jsonl")
metric_logger = "DiskLogger"
if len(args.wandb_api_key) > 0:
    metric_logger = "WandBLogger"

Path(args.tune_config_name).open("w").write(
    template.render(
        train_path=train_path, 
        log_dir=args.log_dir, 
        model_dir=args.model_dir, 
        model_output_dir=args.model_output_dir,
        metric_logger=metric_logger
    )
)
```

lora\_finetune.yaml ì½”ë“œ ìŠ¤ë‹ˆí«

```yaml
# Model arguments
model:
...

# Tokenizer
tokenizer:
  _component_: torchtune.models.phi3.phi3_mini_tokenizer
  path: {{model_dir}}/tokenizer.model
  max_seq_len: null

# Checkpointer
checkpointer:
  _component_: torchtune.training.FullModelHFCheckpointer
  checkpoint_dir: {{model_dir}}
  checkpoint_files: [
    model-00001-of-00002.safetensors,
    model-00002-of-00002.safetensors
  ]
  recipe_checkpoint: null
  output_dir: {{model_output_dir}}
  model_type: PHI3_MINI
resume_from_checkpoint: False
save_adapter_weights_only: False

# Dataset
dataset:
    _component_: torchtune.datasets.instruct_dataset
    source: json
    data_files: {{train_path}}
    column_map:
        input: instruction
        output: output
    train_on_input: False
    packed: False
    split: train
seed: null
shuffle: True

# Logging
output_dir: {{log_dir}}/lora_finetune_output
metric_logger:
  _component_: torchtune.training.metric_logging.{{metric_logger}}
  log_dir: {{log_dir}}/training_logs
log_every_n_steps: 1
log_peak_memory_stats: False

...
```

ì´ ì„¤ì •ì—ì„œëŠ”

1. ìŠ¤í¬ë¦½íŠ¸ê°€ í…œí”Œë¦¿ YAML íŒŒì¼ì„ ì½ê³  ì ì ˆí•œ ê²½ë¡œì™€ êµ¬ì„±ì„ ë™ì ìœ¼ë¡œ ì‚½ì…í•©ë‹ˆë‹¤.
2. `train_path, log_dir, model_dir, model_output_dir`ì€ í™˜ê²½ì˜ ë™ì ìœ¼ë¡œ í• ë‹¹ëœ ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì±„ì›Œì ¸ YAML íŒŒì¼ì´ ì‹¤ì œ ì €ì¥ ìœ„ì¹˜ë¥¼ ë°˜ì˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.
3. `metric_logger`ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ â€œ`DiskLogger`â€ë¡œ ì„¤ì •ë˜ì§€ë§Œ ì‚¬`wandb_api_key`ë¥¼ ì œê³µí•˜ë©´ â€œ`WandBLogger`â€ë¡œ ë³€ê²½ë˜ì–´ ìœ ì—°í•œ ë©”íŠ¸ë¦­ ë¡œê¹… êµ¬ì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ì´ ì ‘ê·¼ ë°©ì‹ì€ Azure MLì˜ Azure Blob ìŠ¤í† ë¦¬ì§€ ë§ˆìš´íŒ…ì— ì˜í•´ ê²½ë¡œê°€ ë™ì ìœ¼ë¡œ í• ë‹¹ë˜ëŠ” ê²½ìš°ì—ë„ ì„¤ì • íŒŒì¼ì´ í•­ìƒ í™˜ê²½ê³¼ ë™ê¸°í™”ë˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.

### 3.4. ë¡œê¹… <a href="#id-8e09" id="id-8e09"></a>

torchtune CLIë¡œ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•  ë•Œ ë¡œê¹…ì— MLflowë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì–´ë µìŠµë‹ˆë‹¤. ëŒ€ì‹  torchtuneì˜ `DiskLogger` ë˜ëŠ” `WandBLogger`ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\
`DiskLogger` ì˜µì…˜ì€ ì§€í‘œ(metric)ê³¼ í›ˆë ¨ ì •ë³´ë¥¼ ë””ìŠ¤í¬(ì˜ˆ: Blob ìŠ¤í† ë¦¬ì§€)ì— ì§ì ‘ ê¸°ë¡í•˜ë¯€ë¡œ MLFlowë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš°ì— ì í•©í•©ë‹ˆë‹¤. ë˜ëŠ” Weight\&Bias (WandB) ê³„ì •ê³¼ API í‚¤ê°€ ìˆëŠ” ê²½ìš°, `WandBLogger`ë¥¼ ì‚¬ìš©í•˜ì—¬ WandB ëŒ€ì‹œë³´ë“œì— ì§€í‘œë¥¼ ê¸°ë¡í•˜ì—¬ ì›ê²© ì•¡ì„¸ìŠ¤ì™€ í›ˆë ¨ ì§„í–‰ ìƒí™©ì˜ ì‹œê°í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ torchtune í”„ë ˆì„ì›Œí¬ ë‚´ì—ì„œ ê°•ë ¥í•œ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

## 4. Azure ML í›ˆë ¨ <a href="#id-4bd1" id="id-4bd1"></a>

***

ì´ ì„¹ì…˜ì„ ì½ê¸° ì „ì— Azure ML í›ˆë ¨ ë° ì„œë¹™ì— ëŒ€í•œ ê¸°ë³¸ ê°€ì´ë“œëŠ” Azure ê³µì‹ ê°€ì´ë“œì™€ ì§€ë‚œ ë¸”ë¡œê·¸([ë¸”ë¡œê·¸ 1](https://techcommunity.microsoft.com/blog/machinelearningblog/finetune-small-language-model-slm-phi-3-using-azure-machine-learning/4130399), [ë¸”ë¡œê·¸ 2](https://techcommunity.microsoft.com/blog/machinelearningblog/fine-tuning-florence-2-for-vqa-visual-question-answering-using-the-azure-ml-pyth/4181123))ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

#### 4.1. ë°ì´í„° ì„¸íŠ¸ ì¤€ë¹„ <a href="#fea6" id="fea6"></a>

torchtuneì€ ì—¬ëŸ¬ ë°ì´í„° ì„¸íŠ¸ ì˜µì…˜ì„ ì œê³µí•˜ì§€ë§Œ, ì´ ë¸”ë¡œê·¸ì—ì„œëŠ” í—ˆê¹…í˜ì´ìŠ¤ ë°ì´í„° ì„¸íŠ¸ë¥¼ jsonìœ¼ë¡œ ì €ì¥í•˜ê³  Azure Blob ë°ì´í„° ìŠ¤í† ì–´ì— Data assetìœ¼ë¡œ ì €ì¥í•˜ëŠ” ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ë°ì´í„° ì„¸íŠ¸ë¥¼ ì§ì ‘ ë¹Œë“œí•˜ê³  ì¦ê°•í•˜ëŠ” ë²•ì€ [í•©ì„± ë°ì´í„° ìƒì„±ì„ ë‹¤ë£¨ëŠ” ë¸”ë¡œê·¸](https://techcommunity.microsoft.com/blog/azure-ai-services-blog/generate-synthetic-qnas-from-real-world-data-on-azure/4202053)ì™€ [ê¹ƒí—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬](https://github.com/Azure/synthetic-qa-generation)ë¥¼ ì°¸ì¡°í•˜ê¸° ë°”ëë‹ˆë‹¤.

#### SFTì™€ KDì— ì‚¬ìš©í•˜ëŠ” Instruction ë°ì´í„° ì„¸íŠ¸ <a href="#id-6aed" id="id-6aed"></a>

ë°ì´í„° ì„¸íŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” ê²ƒì€ ì–´ë µì§€ ì•Šì§€ë§Œ ì—´ ì´ë¦„ì„ yaml íŒŒì¼ì˜ ì‚¬ì–‘ê³¼ ì¼ì¹˜í•˜ë„ë¡ ë³€í™˜í•˜ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”.

```python
dataset = load_dataset("HuggingFaceH4/helpful_instructions", name="self_instruct", split="train[:10%]")
dataset = dataset.rename_column('prompt', 'instruction')
dataset = dataset.rename_column('completion', 'output')

print(f"Loaded Dataset size: {len(dataset)}")

if IS_DEBUG:
    logger.info(f"Activated Debug mode. The number of sample was resampled to 1000.")
    dataset = dataset.select(range(800))
    print(f"Debug Dataset size: {len(dataset)}")

logger.info(f"Save dataset to {SFT_DATA_DIR}")
dataset = dataset.train_test_split(test_size=0.2)
train_dataset = dataset['train']
train_dataset.to_json(f"{SFT_DATA_DIR}/train.jsonl", force_ascii=False)
test_dataset = dataset['test']
test_dataset.to_json(f"{SFT_DATA_DIR}/eval.jsonl", force_ascii=False)
```

#### DPOìš© Preference ë°ì´í„° ì„¸íŠ¸ <a href="#id-4317" id="id-4317"></a>

Preference ë°ì´í„° ì„¸íŠ¸ì˜ ê²½ìš° ì±„íŒ… í…œí”Œë¦¿ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” ì½”ë“œ ì˜ˆì œì…ë‹ˆë‹¤.

```python
def convert_to_preference_format(dataset):
    json_format = [
        {
            "chosen_conversations": [
                {"content": row["prompt"], "role": "user"},
                {"content": row["chosen"], "role": "assistant"}
            ],
            "rejected_conversations": [
                {"content": row["prompt"], "role": "user"},
                {"content": row["rejected"], "role": "assistant"}
            ]
        }
        for row in dataset
    ]
    return json_format

# Load dataset from the hub
data_path = "jondurbin/truthy-dpo-v0.1"   
dataset = load_dataset(data_path, split="train")

print(f"Dataset size: {len(dataset)}")
# if IS_DEBUG:
#     logger.info(f"Activated Debug mode. The number of sample was resampled to 1000.")
#     dataset = dataset.select(range(800))

logger.info(f"Save dataset to {DPO_DATA_DIR}")
dataset = dataset.train_test_split(test_size=0.2)
train_dataset = dataset['train']
test_dataset = dataset['test']

train_dataset = convert_to_preference_format(train_dataset)
test_dataset = convert_to_preference_format(test_dataset)

with open(f"{DPO_DATA_DIR}/train.jsonl", "w") as f:
    json.dump(train_dataset, f, ensure_ascii=False, indent=4)
    
with open(f"{DPO_DATA_DIR}/eval.jsonl", "w") as f:
    json.dump(test_dataset, f, ensure_ascii=False, indent=4)
```

### 4.2. Environment asset <a href="#id-18ba" id="id-18ba"></a>

íë ˆì´íŒ…ëœ í™˜ê²½ì„ ê¸°ë°˜ìœ¼ë¡œ ëª…ë ¹ì— `pip install`ì„ ì¶”ê°€í•˜ê±°ë‚˜ conda ê¸°ë°˜ ì‚¬ìš©ì ì§€ì • í™˜ê²½ì„ ì¶”ê°€í•  ìˆ˜ ìˆì§€ë§Œ ì´ ë¸”ë¡œê·¸ì—ì„œëŠ” docker ê¸°ë°˜ ì‚¬ìš©ì ì§€ì • í™˜ê²½ì„ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” Dockerfile ì˜ˆì‹œì…ë‹ˆë‹¤.

```docker
FROM mcr.microsoft.com/aifx/acpt/stable-ubuntu2004-cu124-py310-torch241:biweekly.202410.2

# Install pip dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt --no-cache-dir

# Inference requirements
COPY --from=mcr.microsoft.com/azureml/o16n-base/python-assets:20230419.v1 /artifacts /var/

RUN /var/requirements/install_system_requirements.sh && \
    cp /var/configuration/rsyslog.conf /etc/rsyslog.conf && \
    cp /var/configuration/nginx.conf /etc/nginx/sites-available/app && \
    ln -sf /etc/nginx/sites-available/app /etc/nginx/sites-enabled/app && \
    rm -f /etc/nginx/sites-enabled/default
ENV SVDIR=/var/runit
ENV WORKER_TIMEOUT=400
EXPOSE 5001 8883 8888

# support Deepspeed launcher requirement of passwordless ssh login
RUN apt-get update
RUN apt-get install -y openssh-server openssh-client

RUN MAX_JOBS=4 pip install flash-attn==2.6.3 --no-build-isolation
```

> \[íŒ] Ubuntu 22.04ë¡œ ì»¨í…Œì´ë„ˆë¥¼ ë¹Œë“œí•˜ëŠ” ê²½ìš° `liblttng-ust0` ê´€ë ¨ íŒ¨í‚¤ì§€/ì¢…ì†ì„±ì„ ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì»¨í…Œì´ë„ˆë¥¼ ë¹Œë“œí•  ë•Œ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. ì•„ë˜ì˜ ì½”ë“œ ìŠ¤ë‹ˆí«ì„ ì°¸ì¡°í•˜ê¸° ë°”ëë‹ˆë‹¤.

```docker
FROM mcr.microsoft.com/aifx/acpt/stable-ubuntu2204-cu124-py310-torch250:biweekly.202410.2
...
# Remove packages or dependencies related to liblttng-ust0.
# Starting from Ubuntu 22.04, liblttng-ust0 has been updated to liblttng-ust1 package, deprecating liblttng-ust0 for compatibility reasons. 
# If you build a docker file on Ubuntu 22.04 without including this syntax, you will get the following liblttng-ust0 error:
# -- Package 'liblttng-ust0' has no installation candidate
RUN sed -i '/liblttng-ust0/d' /var/requirements/system_requirements.txt
...
```

### 4.3. í›ˆë ¨ ì‘ì—… ì‹œì‘ <a href="#fa20" id="fa20"></a>

ì•„ë˜ ì½”ë“œ ìŠ¤ë‹ˆí«ì€ í›ˆë ¨ ì‘ì—…ì„ ìœ„í•œ ì»´í“¨íŒ… í´ëŸ¬ìŠ¤í„°ë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤. ì´ ëª…ë ¹(`command`)ì„ í†µí•´ ì‚¬ìš©ìëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ì‚¬í•­ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

* `inputs` - ëª…ë ¹ì— ì´ë¦„ ê°’ ìŒì„ ì‚¬ìš©í•˜ëŠ” ì…ë ¥ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
* `code` - ëª…ë ¹ì„ ì‹¤í–‰í•  ì½”ë“œê°€ ìˆëŠ” ê²½ë¡œì…ë‹ˆë‹¤.
* `compute` - ëª…ë ¹ì´ ì‹¤í–‰ë  ì»´í“¨íŒ…ì…ë‹ˆë‹¤. ë¡œì»¬ ì»´í“¨í„°ì—ì„œ ì‹¤í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
* `command` - `${{inputs.<input_name>}}` í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ëª…ë ¹ì—ì„œ ì‹¤í–‰í•´ì•¼ í•˜ëŠ” ëª…ë ¹ì…ë‹ˆë‹¤. íŒŒì¼ì´ë‚˜ í´ë”ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ë ¤ë©´ `Input` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `Input` í´ë˜ìŠ¤ëŠ” ì„¸ ê°€ì§€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:
* `environment` - ëª…ë ¹ì´ ì‹¤í–‰ë˜ëŠ” ë° í•„ìš”í•œ í™˜ê²½ì…ë‹ˆë‹¤. ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì—ì„œ íë ˆì´íŒ…ëœ (ë¹ŒíŠ¸ì¸) í™˜ê²½ ë˜ëŠ” ì‚¬ìš©ì ì§€ì • í™˜ê²½ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* `instance_count` - ë…¸ë“œ ìˆ˜ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ 1ì…ë‹ˆë‹¤.
* `distribution` - ë¶„ì‚° í›ˆë ¨ì— ì‚¬ìš©ë˜ëŠ” íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤. Azure MLì€ PyTorch, TensorFlow ë° MPI (Message Passing Interface) ê¸°ë°˜ ë¶„ì‚° í›ˆë ¨ì„ ì§€ì›í•©ë‹ˆë‹¤.

```python
from azure.ai.ml import command
from azure.ai.ml import Input
from azure.ai.ml.entities import ResourceConfiguration
from utils.aml_common import get_num_gpus

num_gpu = get_num_gpus(azure_compute_cluster_size)
logger.info(f"Number of GPUs={num_gpu}")

str_command = ""
if USE_BUILTIN_ENV:
    str_env = "azureml://registries/azureml/environments/acpt-pytorch-2.2-cuda12.1/versions/19" # Use built-in Environment asset
    str_command += "pip install -r requirements.txt && "
else:
    str_env = f"{azure_env_name}@latest" # Use Curated (built-in) Environment asset
    
if num_gpu > 1:
    tune_recipe = "lora_finetune_distributed"    
    str_command += "python launcher_distributed.py "
else:
    tune_recipe = "lora_finetune_single_device"
    str_command += "python launcher_single.py "
    
if len(wandb_api_key) > 0 or wandb_api_key is not None:
    str_command += "--wandb_api_key ${{inputs.wandb_api_key}} \
            --wandb_project ${{inputs.wandb_project}} \
            --wandb_watch ${{inputs.wandb_watch}} "

str_command += "--train_dir ${{inputs.train_dir}} \
            --hf_token ${{inputs.hf_token}} \
            --tune_recipe ${{inputs.tune_recipe}} \
            --tune_action ${{inputs.tune_action}} \
            --model_id ${{inputs.model_id}} \
            --model_dir ${{inputs.model_dir}} \
            --log_dir ${{inputs.log_dir}} \
            --model_output_dir ${{inputs.model_output_dir}} \
            --tune_config_name ${{inputs.tune_config_name}}"
logger.info(f"Tune recipe: {tune_recipe}")

job = command(
    inputs=dict(
        #train_dir=Input(type="uri_folder", path=SFT_DATA_DIR), # Get data from local path
        train_dir=Input(path=f"{AZURE_SFT_DATA_NAME}@latest"),  # Get data from Data asset
        hf_token=HF_TOKEN,
        wandb_api_key=wandb_api_key,
        wandb_project=wandb_project,
        wandb_watch=wandb_watch,
        tune_recipe=tune_recipe,
        tune_action="fine-tune,run-quant",
        model_id=HF_MODEL_NAME_OR_PATH,
        model_dir="./model",
        log_dir="./outputs/log",
        model_output_dir="./outputs",
        tune_config_name="lora_finetune.yaml"
    ),
    code="./scripts",  # local path where the code is stored
    compute=azure_compute_cluster_name,
    command=str_command,
    environment=str_env,
    instance_count=1,
    distribution={
        "type": "PyTorch",
        "process_count_per_instance": num_gpu, # For multi-gpu training set this to an integer value more than 1
    },
)

returned_job = ml_client.jobs.create_or_update(job)
logger.info("""Started training job. Now a dedicated Compute Cluster for training is provisioned and the environment
required for training is automatically set up from Environment.

If you have set up a new custom Environment, it will take approximately 20 minutes or more to set up the Environment before provisioning the training cluster.
""")
ml_client.jobs.stream(returned_job.name)
```

### 4.4. ë¡œê¹… <a href="#b2be" id="b2be"></a>

`torchtune.training.metric_logging.DiskLogger` ë˜ëŠ” `torchtune.training.metric_logging.WandBLogger`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. `DiskLogger`ë¥¼ ì ìš©í•  ë•Œ ì €ì¥ ê²½ë¡œëŠ” ì¶œë ¥ì˜ í•˜ìœ„ í´ë”ì—¬ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Azure ML UIì—ì„œ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\
ì•„ë˜ëŠ” `DiskLogger`ê°€ ì ìš©ëœ ìŠ¤í¬ë¦°ìƒ·ì…ë‹ˆë‹¤.

<figure><img src="https://miro.medium.com/v2/resize:fit:1400/1*NGc025mAMTQVJ6bAuatXFg.png" alt="" height="114" width="700"><figcaption></figcaption></figure>

ì•„ë˜ëŠ” `WandBLogger`ê°€ ì ìš©ëœ ìŠ¤í¬ë¦°ìƒ·ì…ë‹ˆë‹¤.

<figure><img src="https://miro.medium.com/v2/resize:fit:1400/1*mHFLVT1eYLGHoTRB4flYvQ.png" alt="" height="434" width="700"><figcaption></figcaption></figure>

ëª¨ë“  ì¶”ê°€ í›ˆë ¨ ê¸°ë¡ì€ Azure MLì˜ `user_logs` í´ë”ì— ê¸°ë¡ë©ë‹ˆë‹¤. ì•„ë˜ëŠ” `Standard_NC48ads_A100_v4`(NVIDIA A100 GPU x 2ea)ë¥¼ ì»´í“¨íŒ… í´ëŸ¬ìŠ¤í„°ë¡œ ì‚¬ìš©í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.

<figure><img src="https://miro.medium.com/v2/resize:fit:1400/1*5zPrAIYoMHX6x0pqyUdExw.png" alt="" height="563" width="700"><figcaption></figcaption></figure>

í›ˆë ¨ ì½”ë“œì—ì„œ íŒŒì¸ íŠœë‹-í‰ê°€-ì–‘ìí™” íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•  ë•Œ ì–‘ìí™”ëœ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì €ì¥í•˜ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”. í–¥í›„ ìƒí˜¸ê°„ ëª¨ë¸ ë¹„êµë¥¼ ìœ„í•´ ì–‘ìí™”í•˜ê¸° ì „ì˜ ì›ë˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ë„ ê°™ì´ ì €ì¥í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

<figure><img src="https://miro.medium.com/v2/resize:fit:1400/1*WJRAh52-m2x0fP-EBaPYcg.png" alt="" height="418" width="700"><figcaption></figcaption></figure>

### 4.5. ëª¨ë¸ ë“±ë¡ <a href="#id-5820" id="id-5820"></a>

torchtuneìœ¼ë¡œ ëª¨ë¸ì„ íŒŒì¸ íŠœë‹í•˜ê³  ì–‘ìí™”í–ˆìœ¼ë©´ Azure MLì— [Model asset](https://learn.microsoft.com/ko-kr/azure/machine-learning/how-to-create-data-assets)ìœ¼ë¡œ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë“±ë¡ í”„ë¡œì„¸ìŠ¤ëŠ” ëª¨ë¸ ê´€ë¦¬ ë° ë°°í¬ë¥¼ ë³´ë‹¤ íš¨ìœ¨ì ì´ê³  ì²´ê³„ì ìœ¼ë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. Model asset ë“±ë¡ì€ ì•„ë˜ì™€ ê°™ì€ ì´ì ì´ ìˆìŠµë‹ˆë‹¤.

* **ë²„ì „ ê´€ë¦¬**: Azure MLì˜ Model assetì„ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì˜ ì—¬ëŸ¬ ë²„ì „ì„ ìœ ì§€ ê´€ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¸ íŠœë‹ êµ¬ì„±ì´ë“  ë³€ê²½ëœ ì–‘ìí™” ë°©ì‹ì´ë“  ëª¨ë¸ì˜ ê° ë°˜ë³µ(iteration)ì„ ì‹ ê·œ ë²„ì „ìœ¼ë¡œ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ ì§„í™”ë¥¼ ì‰½ê²Œ ì¶”ì í•˜ê³ , ë²„ì „ ê°„ ì„±ëŠ¥ì„ ë¹„êµí•˜ê³ , í•„ìš”í•œ ê²½ìš° ì´ì „ ë²„ì „ìœ¼ë¡œ ë¡¤ë°±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ì¤‘ì•™ ì €ì¥ì†Œ**: Model assetìœ¼ë¡œ ë“±ë¡í•˜ë©´ ì¤‘ì•™ ì €ì¥ì†Œì— ì €ì¥ë©ë‹ˆë‹¤. ì´ ì €ì¥ì†Œë¥¼ í†µí•´ ì¡°ì§ ë‚´ ë‹¤ë¥¸ íŒ€ì›ì´ë‚˜ í”„ë¡œì íŠ¸ì—ì„œ ì‰½ê²Œ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ëŸ¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ í˜‘ì—…í•˜ê³  ì¼ê´€ëœ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ë°°í¬ ì¤€ë¹„ ì™„ë£Œ**: Azure MLì— ì—ì…‹ìœ¼ë¡œ ë“±ë¡ëœ ëª¨ë¸ì€ ì§ì ‘ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, ë“±ë¡ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì—”ë“œí¬ì¸íŠ¸, ì¼ê´„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ë˜ëŠ” ê¸°íƒ€ ì„œë¹„ìŠ¤ ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ì •í•˜ì—¬ ë°°í¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°„ì†Œí™”í•˜ê³  ì ì¬ì ì¸ ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **ë©”íƒ€ë°ì´í„° ê´€ë¦¬**: ëª¨ë¸ê³¼ í•¨ê»˜ ê´€ë ¨ ë©”íƒ€ë°ì´í„°(ì˜ˆ: í›ˆë ¨ ì„¤ì •, í™˜ê²½ ì„¸ë¶€ ì •ë³´ ë° í‰ê°€ ì§€í‘œ)ë¥¼ Model assetì— ì €ì¥í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ ë©”íƒ€ë°ì´í„°ëŠ” ì¬í˜„ì„±ê³¼ ë‹¤ì–‘í•œ ì¡°ê±´ì—ì„œì˜ ëª¨ë¸ ì„±ëŠ¥ì„ ì´í•´í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.

ë‹¤ìŒì€ Model assetì„ ë“±ë¡í•˜ê³  ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ì½”ë“œ ìŠ¤ë‹ˆí«ì…ë‹ˆë‹¤.

```python
def get_or_create_model_asset(ml_client, model_name, job_name, model_dir="outputs", model_type="custom_model", 
                              download_quantized_model_only=False, update=False):
    
    try:
        latest_model_version = max([int(m.version) for m in ml_client.models.list(name=model_name)])
        if update:
            raise ResourceExistsError('Found Model asset, but will update the Model.')
        else:
            model_asset = ml_client.models.get(name=model_name, version=latest_model_version)
            print(f"Found Model asset: {model_name}. Will not create again")
    except (ResourceNotFoundError, ResourceExistsError) as e:
        print(f"Exception: {e}")
        model_path = f"azureml://jobs/{job_name}/outputs/artifacts/paths/{model_dir}"    
        if download_quantized_model_only:
            model_path = f"azureml://jobs/{job_name}/outputs/artifacts/paths/{model_dir}/quant"    
        run_model = Model(
            name=model_name,        
            path=model_path,
            description="Model created from run.",
            type=model_type # mlflow_model, custom_model, triton_model
        )
        model_asset = ml_client.models.create_or_update(run_model)
        print(f"Created Model asset: {model_name}")

    return model_asset


model = get_or_create_model_asset(ml_client, azure_model_name, job_name, model_dir, model_type="custom_model", 
                                  download_quantized_model_only=True, update=False)
                                  
# Download the model (this is optional)
DOWNLOAD_TO_LOCAL = False
local_model_dir = "./artifact_downloads_dpo"

if DOWNLOAD_TO_LOCAL:
    os.makedirs(local_model_dir, exist_ok=True)
    ml_client.models.download(name=azure_model_name, download_path=local_model_dir, version=model.version)
```

ì—”ë“œ-íˆ¬-ì—”ë“œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” í•¸ì¦ˆì˜¨ë©ì„ [https://github.com/Azure/torchtune-azureml](https://github.com/Azure/torchtune-azureml) ì— ê³µê°œí–ˆìŠµë‹ˆë‹¤. torchtuneê³¼Azure MLì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¸ íŠœë‹/í‰ê°€/ì–‘ìí™”ë¥¼ ì‰½ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤.

### References <a href="#id-0f65" id="id-0f65"></a>

* [Azure ML Fine-tuning (Florence-2) Blog](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/fine-tuning-florence-2-for-vqa-visual-question-answering-using/ba-p/4181123)
* [Synthetic QnA Generation Blog](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/generate-synthetic-qnas-from-real-world-data-on-azure/ba-p/4202053)
* [torchtune official website](https://github.com/pytorch/torchtune)
* [Fine-tune Meta Llama 3.1 models using torchtune on Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/fine-tune-meta-llama-3-1-models-using-torchtune-on-amazon-sagemaker/)\
